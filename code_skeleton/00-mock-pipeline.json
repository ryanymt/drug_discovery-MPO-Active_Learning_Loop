{
  "components": {
    "comp-patch-spec": {
      "executorLabel": "exec-patch-spec",
      "inputDefinitions": {
        "parameters": {
          "base_gcs_path": {
            "parameterType": "STRING"
          },
          "loop_id": {
            "parameterType": "STRING"
          },
          "mode": {
            "parameterType": "STRING"
          },
          "spec_json_str": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "parameters": {
          "Output": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-patch-spec-10": {
      "executorLabel": "exec-patch-spec-10",
      "inputDefinitions": {
        "parameters": {
          "base_gcs_path": {
            "parameterType": "STRING"
          },
          "loop_id": {
            "parameterType": "STRING"
          },
          "mode": {
            "parameterType": "STRING"
          },
          "spec_json_str": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "parameters": {
          "Output": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-patch-spec-11": {
      "executorLabel": "exec-patch-spec-11",
      "inputDefinitions": {
        "parameters": {
          "base_gcs_path": {
            "parameterType": "STRING"
          },
          "loop_id": {
            "parameterType": "STRING"
          },
          "mode": {
            "parameterType": "STRING"
          },
          "spec_json_str": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "parameters": {
          "Output": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-patch-spec-2": {
      "executorLabel": "exec-patch-spec-2",
      "inputDefinitions": {
        "parameters": {
          "base_gcs_path": {
            "parameterType": "STRING"
          },
          "loop_id": {
            "parameterType": "STRING"
          },
          "mode": {
            "parameterType": "STRING"
          },
          "spec_json_str": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "parameters": {
          "Output": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-patch-spec-3": {
      "executorLabel": "exec-patch-spec-3",
      "inputDefinitions": {
        "parameters": {
          "base_gcs_path": {
            "parameterType": "STRING"
          },
          "loop_id": {
            "parameterType": "STRING"
          },
          "mode": {
            "parameterType": "STRING"
          },
          "spec_json_str": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "parameters": {
          "Output": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-patch-spec-4": {
      "executorLabel": "exec-patch-spec-4",
      "inputDefinitions": {
        "parameters": {
          "base_gcs_path": {
            "parameterType": "STRING"
          },
          "loop_id": {
            "parameterType": "STRING"
          },
          "mode": {
            "parameterType": "STRING"
          },
          "spec_json_str": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "parameters": {
          "Output": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-patch-spec-5": {
      "executorLabel": "exec-patch-spec-5",
      "inputDefinitions": {
        "parameters": {
          "base_gcs_path": {
            "parameterType": "STRING"
          },
          "loop_id": {
            "parameterType": "STRING"
          },
          "mode": {
            "parameterType": "STRING"
          },
          "spec_json_str": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "parameters": {
          "Output": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-patch-spec-6": {
      "executorLabel": "exec-patch-spec-6",
      "inputDefinitions": {
        "parameters": {
          "base_gcs_path": {
            "parameterType": "STRING"
          },
          "loop_id": {
            "parameterType": "STRING"
          },
          "mode": {
            "parameterType": "STRING"
          },
          "spec_json_str": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "parameters": {
          "Output": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-patch-spec-7": {
      "executorLabel": "exec-patch-spec-7",
      "inputDefinitions": {
        "parameters": {
          "base_gcs_path": {
            "parameterType": "STRING"
          },
          "loop_id": {
            "parameterType": "STRING"
          },
          "mode": {
            "parameterType": "STRING"
          },
          "spec_json_str": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "parameters": {
          "Output": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-patch-spec-8": {
      "executorLabel": "exec-patch-spec-8",
      "inputDefinitions": {
        "parameters": {
          "base_gcs_path": {
            "parameterType": "STRING"
          },
          "loop_id": {
            "parameterType": "STRING"
          },
          "mode": {
            "parameterType": "STRING"
          },
          "spec_json_str": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "parameters": {
          "Output": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-patch-spec-9": {
      "executorLabel": "exec-patch-spec-9",
      "inputDefinitions": {
        "parameters": {
          "base_gcs_path": {
            "parameterType": "STRING"
          },
          "loop_id": {
            "parameterType": "STRING"
          },
          "mode": {
            "parameterType": "STRING"
          },
          "spec_json_str": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "parameters": {
          "Output": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-submit-batch-job": {
      "executorLabel": "exec-submit-batch-job",
      "inputDefinitions": {
        "parameters": {
          "job_spec": {
            "description": "The entire Batch job specification in JSON format as a string.",
            "parameterType": "STRING"
          },
          "location": {
            "description": "The Google Cloud region for the job.",
            "parameterType": "STRING"
          },
          "project": {
            "description": "The Google Cloud project ID.",
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-submit-batch-job-10": {
      "executorLabel": "exec-submit-batch-job-10",
      "inputDefinitions": {
        "parameters": {
          "job_spec": {
            "description": "The entire Batch job specification in JSON format as a string.",
            "parameterType": "STRING"
          },
          "location": {
            "description": "The Google Cloud region for the job.",
            "parameterType": "STRING"
          },
          "project": {
            "description": "The Google Cloud project ID.",
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-submit-batch-job-11": {
      "executorLabel": "exec-submit-batch-job-11",
      "inputDefinitions": {
        "parameters": {
          "job_spec": {
            "description": "The entire Batch job specification in JSON format as a string.",
            "parameterType": "STRING"
          },
          "location": {
            "description": "The Google Cloud region for the job.",
            "parameterType": "STRING"
          },
          "project": {
            "description": "The Google Cloud project ID.",
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-submit-batch-job-2": {
      "executorLabel": "exec-submit-batch-job-2",
      "inputDefinitions": {
        "parameters": {
          "job_spec": {
            "description": "The entire Batch job specification in JSON format as a string.",
            "parameterType": "STRING"
          },
          "location": {
            "description": "The Google Cloud region for the job.",
            "parameterType": "STRING"
          },
          "project": {
            "description": "The Google Cloud project ID.",
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-submit-batch-job-3": {
      "executorLabel": "exec-submit-batch-job-3",
      "inputDefinitions": {
        "parameters": {
          "job_spec": {
            "description": "The entire Batch job specification in JSON format as a string.",
            "parameterType": "STRING"
          },
          "location": {
            "description": "The Google Cloud region for the job.",
            "parameterType": "STRING"
          },
          "project": {
            "description": "The Google Cloud project ID.",
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-submit-batch-job-4": {
      "executorLabel": "exec-submit-batch-job-4",
      "inputDefinitions": {
        "parameters": {
          "job_spec": {
            "description": "The entire Batch job specification in JSON format as a string.",
            "parameterType": "STRING"
          },
          "location": {
            "description": "The Google Cloud region for the job.",
            "parameterType": "STRING"
          },
          "project": {
            "description": "The Google Cloud project ID.",
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-submit-batch-job-5": {
      "executorLabel": "exec-submit-batch-job-5",
      "inputDefinitions": {
        "parameters": {
          "job_spec": {
            "description": "The entire Batch job specification in JSON format as a string.",
            "parameterType": "STRING"
          },
          "location": {
            "description": "The Google Cloud region for the job.",
            "parameterType": "STRING"
          },
          "project": {
            "description": "The Google Cloud project ID.",
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-submit-batch-job-6": {
      "executorLabel": "exec-submit-batch-job-6",
      "inputDefinitions": {
        "parameters": {
          "job_spec": {
            "description": "The entire Batch job specification in JSON format as a string.",
            "parameterType": "STRING"
          },
          "location": {
            "description": "The Google Cloud region for the job.",
            "parameterType": "STRING"
          },
          "project": {
            "description": "The Google Cloud project ID.",
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-submit-batch-job-7": {
      "executorLabel": "exec-submit-batch-job-7",
      "inputDefinitions": {
        "parameters": {
          "job_spec": {
            "description": "The entire Batch job specification in JSON format as a string.",
            "parameterType": "STRING"
          },
          "location": {
            "description": "The Google Cloud region for the job.",
            "parameterType": "STRING"
          },
          "project": {
            "description": "The Google Cloud project ID.",
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-submit-batch-job-8": {
      "executorLabel": "exec-submit-batch-job-8",
      "inputDefinitions": {
        "parameters": {
          "job_spec": {
            "description": "The entire Batch job specification in JSON format as a string.",
            "parameterType": "STRING"
          },
          "location": {
            "description": "The Google Cloud region for the job.",
            "parameterType": "STRING"
          },
          "project": {
            "description": "The Google Cloud project ID.",
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-submit-batch-job-9": {
      "executorLabel": "exec-submit-batch-job-9",
      "inputDefinitions": {
        "parameters": {
          "job_spec": {
            "description": "The entire Batch job specification in JSON format as a string.",
            "parameterType": "STRING"
          },
          "location": {
            "description": "The Google Cloud region for the job.",
            "parameterType": "STRING"
          },
          "project": {
            "description": "The Google Cloud project ID.",
            "parameterType": "STRING"
          }
        }
      }
    }
  },
  "deploymentSpec": {
    "executors": {
      "exec-patch-spec": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "patch_spec"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.15.2' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef patch_spec(\n    spec_json_str: str,\n    loop_id: str,\n    mode: str,\n    base_gcs_path: str\n) -> str:\n    import json\n    import re\n\n    spec = json.loads(spec_json_str)\n\n    # Helper to clean command string\n    def update_cmd(container, old, new):\n        cmds = container['commands']\n        # If commands is list of strings\n        for i, c in enumerate(cmds):\n            if old in c:\n                cmds[i] = c.replace(old, new)\n        # If it's a -c \"...\" structure (common in our specs)\n        if len(cmds) > 1 and cmds[0] == \"-c\": # bash -c ...\n             cmds[1] = cmds[1].replace(old, new)\n\n    task = spec['taskGroups'][0]['taskSpec']['runnables'][0]\n    container = task['container']\n\n    # --- Logic ---\n    if mode == \"pocket2mol\":\n        # Output: /output/{loop_id}/generation\n        new_out = f\"{base_gcs_path}/output/{loop_id}/generation\"\n        # Naive replace of common flag patterns\n        # We rely on the template having a known structure or placeholders would be better.\n        # Let's assume the template has specific flags we can regex sub.\n        cmd = container['commands'][2] # Assuming bash -c \"...\" is at index 2 or 1\n        # Fix: The templates usually have [\"/bin/bash\", \"-c\", \"python ...\"] or similar\n        # Let's handle the string content of the last arg\n        cmd_idx = -1\n        cmd_str = container['commands'][cmd_idx]\n\n        cmd_str = re.sub(r\"--outdir\\s+\\S+\", f\"--outdir {new_out}\", cmd_str)\n        cmd_str = re.sub(r\"num_samples: \\d+\", \"num_samples: 50\", cmd_str) # Fast test\n\n        container['commands'][cmd_idx] = cmd_str\n\n    elif mode == \"gnina\" or mode == \"txgemma\" or mode == \"rdkit\":\n        # Input: /output/{loop_id}/generation/SMILES.txt\n        inp_path = f\"{base_gcs_path}/output/{loop_id}/generation/SMILES.txt\"\n\n        cmd_idx = -1\n        cmd_str = container['commands'][cmd_idx]\n\n        if mode == \"txgemma\":\n             cmd_str = re.sub(r\"--input-file\\s+\\S+\", f\"--input-file {inp_path}\", cmd_str)\n        elif mode == \"rdkit\":\n             cmd_str = re.sub(r\"--input_csv\\s+\\S+\", f\"--input_csv {inp_path}\", cmd_str)\n        elif mode == \"gnina\":\n             # Gnina script is positional? Or flags? \n             # Looking at task spec: /usr/local/bin/run_gnina_docking.sh <input> <output>\n             # We just append/replace\n             parts = cmd_str.split()\n             # Finding the script call\n             if \"run_gnina_docking.sh\" in cmd_str:\n                 # Replace the arg after the script\n                 # This is brittle. Let's assume standard arg order from template.\n                 # Better: Use placeholders in template {{INPUT_Path}}\n                 pass\n\n        container['commands'][cmd_idx] = cmd_str\n\n    elif mode == \"joiner\":\n        # Inputs from generation and filters\n        smi = f\"{base_gcs_path}/output/{loop_id}/generation/SMILES.txt\"\n        rd = f\"{base_gcs_path}/input/{loop_id}/filters/rdkit_scores.csv\" \n        tx = f\"{base_gcs_path}/input/{loop_id}/filters/txgemma_results.csv\"\n        # Gnina is a directory\n        gn = f\"{base_gcs_path}/input/{loop_id}/filters/gnina_out\"\n        out = f\"{base_gcs_path}/output/{loop_id}/selection/joined_results.csv\"\n\n        # Command: Copy script -> Run\n        script_src = f\"{base_gcs_path}/data/scripts/join_results.py\"\n\n        # We need to construct the bash command\n        # \"echo 'Starting Join...' && cp /mnt/disks/gcs/data/scripts/join_results.py . && python3 join_results.py ...\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 join_results.py \"\n            f\"--smiles {smi} \"\n            f\"--rdkit {rd} \"\n            f\"--txgemma {tx} \"\n            f\"--gnina {gn} \"\n            f\"--output {out} \"\n            f\"--batch_id {loop_id}\"\n        )\n\n        # Depending on template, we might need to wrap in /bin/bash -c\n        # If template command is [\"python3\", ...], we replace it with [\"/bin/bash\", \"-c\", cmd_str]\n\n        container['command'] = [\"/bin/bash\", \"-c\", cmd_str]\n        # Note: 'command' vs 'commands'. K8s uses 'command', Batch Spec 'commands'. \n        # Check carefully. The template uses 'commands'.\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"selection\":\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/joined_results.csv\"\n        out_sel = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        out_pool = f\"{base_gcs_path}/output/{loop_id}/selection/unlabeled_pool.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/select_active_learning.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 select_active_learning.py \"\n            f\"--input {inp} \"\n            f\"--output_selected {out_sel} \"\n            f\"--output_pool {out_pool} \"\n            f\"--top_n 100\"\n        )\n\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"mock_fep\":\n        # Input: Selected candidates\n        # Output: FEP results (we need to enforce this path in `mock_fep_batch.py` or assume it writes to stdout?)\n        # `mock_fep_batch.py` currently writes to `fep_results.csv` locally or arg?\n        # Let's inspect `mock_fep_batch.py` usage in Spec.\n        # Spec says: `python3 /tmp/mock_fep.py --input ...`\n        # We should add `--output ...` if supported, or rely on defaults.\n        # Let's force output path:\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        out = f\"{base_gcs_path}/output/{loop_id}/oracle/fep_results.csv\"\n\n        # Patch command to include output flag (assuming supported or we pipe it)\n        # `mock_fep_batch.py` logic check needed. Assuming we can pass it.\n        # If not, let's assume it writes to same dir as input?\n        # Safe bet: Explicit arg: `python3 mock_fep.py --input ... --output ...`\n\n        cmd_idx = 1\n        c = container['commands'][cmd_idx]\n        c = re.sub(r\"--input\\s+\\S+\", f\"--input {inp}\", c)\n        c += f\" --output {out}\" # Append output arg\n        container['commands'][cmd_idx] = c\n\n    elif mode == \"trainer\":\n        # Inputs:\n        # 1. Labeled Data (Oracle Output)\n        # 2. Unlabeled Pool (Selection Output)\n        labeled = f\"{base_gcs_path}/output/{loop_id}/oracle/fep_results.csv\"\n        pool = f\"{base_gcs_path}/output/{loop_id}/selection/unlabeled_pool.csv\"\n\n        # Outputs:\n        # 1. Model Artifact\n        # 2. Predictions\n        model_out = f\"{base_gcs_path}/output/{loop_id}/training/proxy_model.json\"\n        pred_out = f\"{base_gcs_path}/output/{loop_id}/training/proxy_predictions.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/train_xgboost.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 train_xgboost.py \"\n            f\"--train {labeled} \"\n            f\"--predict {pool} \"\n            f\"--output_model {model_out} \"\n            f\"--output_predictions {pred_out}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"elite_selector\":\n        # Input: Predictions\n        inp = f\"{base_gcs_path}/output/{loop_id}/training/proxy_predictions.csv\"\n        # Output: Elite Candidates\n        out = f\"{base_gcs_path}/output/{loop_id}/selection_v2/elite_candidates.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/select_elite.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 select_elite.py \"\n            f\"--predictions {inp} \"\n            f\"--output {out} \"\n            f\"--n_elite 40 --n_random 10\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"redocker\":\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection_v2/elite_candidates.csv\"\n        out_dir = f\"{base_gcs_path}/output/{loop_id}/training_data/sdfs\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/redock_batch.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 redock_batch.py \"\n            f\"--input {inp} \"\n            f\"--output_dir {out_dir}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"finetune_launcher\":\n        data_dir = f\"{base_gcs_path}/output/{loop_id}/training_data/sdfs\"\n        # Model output will be a new directory for next cycle\n        model_out_dir = f\"{base_gcs_path}/output/{loop_id}/models/finetuned\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/finetune_launcher.py\"\n\n        # Params for launcher\n        proj = \"gcda-apac-sc\"\n        reg = \"us-central1\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 finetune_launcher.py \"\n            f\"--project {proj} \"\n            f\"--region {reg} \"\n            f\"--training_data_dir {data_dir} \"\n            f\"--output_model_dir {model_out_dir}\"\n            f\"--output_model_dir {model_out_dir}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"mmpbsa_fep\":\n        # Input: Candidates from selection\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        # Output: Results directory (CSV created inside)\n        out = f\"{base_gcs_path}/output/{loop_id}/oracle\"\n\n        # Original: /usr/local/bin/run_mmpbsa.sh --run --id batch_${BATCH_TASK_INDEX}\n        # We need to inject runtime copying of scripts? \n        # Actually, let's keep it simple: Ensure spec mounts correct paths or we override commands.\n        # The spec `mmpbsa-test-job.json` has `cp .../fep_setup.py` hardcoded.\n        # For pipeline, we should assume scripts are in `scripts/` or `input/`.\n\n        # Let's construct a command that:\n        # 1. Copies `fep_setup.py` and `run_mmpbsa.sh` from `scripts/`? \n        #    Or assume they are baked in image? Current status: Baked in image BUT we hotfix them.\n        #    Safe bet: Copy from GCS location defined in `BASE_GCS_PATH`.\n\n        script_dir = f\"{base_gcs_path}/data/scripts/mmpbsa_shards\"\n\n        # Command construction\n        # Note: We need to preserve BATCH_TASK_INDEX env var usage\n        cmd_str = (\n            f\"cp {script_dir}/fep_setup.py /usr/local/bin/fep_setup.py && \"\n            f\"cp {script_dir}/run_mmpbsa.sh /usr/local/bin/run_mmpbsa.sh && \"\n            f\"chmod +x /usr/local/bin/run_mmpbsa.sh /usr/local/bin/fep_setup.py && \"\n            f\"export BATCH_TASK_INDEX=${{BATCH_TASK_INDEX}} && \"\n            f\"/usr/local/bin/run_mmpbsa.sh --run --id batch_${{BATCH_TASK_INDEX}}\"\n        )\n\n        # Update mounts to point to dynamic loop paths if needed?\n        # Actually, mmpbsa READS from `INPUT_DIR`.\n        # By default `INPUT_DIR` is `/mnt/disks/gcs/input`.\n        # We need to ensure that `selected_candidates.csv` is split into `batch_N.csv` there?\n        # OR `run_mmpbsa.sh` reads `batch_N.csv`.\n        # Pipeline Gap: Who splits `selected_candidates.csv` into `batch_0.csv`?\n        # Answer: `stage_mmpbsa_batch` component? Or `selection` step?\n        # Current workflow test used `stage_mmpbsa_test.py`.\n        # We need a `staging` step in pipeline or `selection` output split.\n        # For now, let's assume `selection` outputs a single file and we execute ONE big batch or `run_mmpbsa` handles splitting?\n        # No, `run_mmpbsa.sh` expects `${JOB_ID}.csv`.\n        # We will add a \"Stager\" component later. For integration, we define the hook here.\n\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    return json.dumps(spec)\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-patch-spec-10": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "patch_spec"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.15.2' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef patch_spec(\n    spec_json_str: str,\n    loop_id: str,\n    mode: str,\n    base_gcs_path: str\n) -> str:\n    import json\n    import re\n\n    spec = json.loads(spec_json_str)\n\n    # Helper to clean command string\n    def update_cmd(container, old, new):\n        cmds = container['commands']\n        # If commands is list of strings\n        for i, c in enumerate(cmds):\n            if old in c:\n                cmds[i] = c.replace(old, new)\n        # If it's a -c \"...\" structure (common in our specs)\n        if len(cmds) > 1 and cmds[0] == \"-c\": # bash -c ...\n             cmds[1] = cmds[1].replace(old, new)\n\n    task = spec['taskGroups'][0]['taskSpec']['runnables'][0]\n    container = task['container']\n\n    # --- Logic ---\n    if mode == \"pocket2mol\":\n        # Output: /output/{loop_id}/generation\n        new_out = f\"{base_gcs_path}/output/{loop_id}/generation\"\n        # Naive replace of common flag patterns\n        # We rely on the template having a known structure or placeholders would be better.\n        # Let's assume the template has specific flags we can regex sub.\n        cmd = container['commands'][2] # Assuming bash -c \"...\" is at index 2 or 1\n        # Fix: The templates usually have [\"/bin/bash\", \"-c\", \"python ...\"] or similar\n        # Let's handle the string content of the last arg\n        cmd_idx = -1\n        cmd_str = container['commands'][cmd_idx]\n\n        cmd_str = re.sub(r\"--outdir\\s+\\S+\", f\"--outdir {new_out}\", cmd_str)\n        cmd_str = re.sub(r\"num_samples: \\d+\", \"num_samples: 50\", cmd_str) # Fast test\n\n        container['commands'][cmd_idx] = cmd_str\n\n    elif mode == \"gnina\" or mode == \"txgemma\" or mode == \"rdkit\":\n        # Input: /output/{loop_id}/generation/SMILES.txt\n        inp_path = f\"{base_gcs_path}/output/{loop_id}/generation/SMILES.txt\"\n\n        cmd_idx = -1\n        cmd_str = container['commands'][cmd_idx]\n\n        if mode == \"txgemma\":\n             cmd_str = re.sub(r\"--input-file\\s+\\S+\", f\"--input-file {inp_path}\", cmd_str)\n        elif mode == \"rdkit\":\n             cmd_str = re.sub(r\"--input_csv\\s+\\S+\", f\"--input_csv {inp_path}\", cmd_str)\n        elif mode == \"gnina\":\n             # Gnina script is positional? Or flags? \n             # Looking at task spec: /usr/local/bin/run_gnina_docking.sh <input> <output>\n             # We just append/replace\n             parts = cmd_str.split()\n             # Finding the script call\n             if \"run_gnina_docking.sh\" in cmd_str:\n                 # Replace the arg after the script\n                 # This is brittle. Let's assume standard arg order from template.\n                 # Better: Use placeholders in template {{INPUT_Path}}\n                 pass\n\n        container['commands'][cmd_idx] = cmd_str\n\n    elif mode == \"joiner\":\n        # Inputs from generation and filters\n        smi = f\"{base_gcs_path}/output/{loop_id}/generation/SMILES.txt\"\n        rd = f\"{base_gcs_path}/input/{loop_id}/filters/rdkit_scores.csv\" \n        tx = f\"{base_gcs_path}/input/{loop_id}/filters/txgemma_results.csv\"\n        # Gnina is a directory\n        gn = f\"{base_gcs_path}/input/{loop_id}/filters/gnina_out\"\n        out = f\"{base_gcs_path}/output/{loop_id}/selection/joined_results.csv\"\n\n        # Command: Copy script -> Run\n        script_src = f\"{base_gcs_path}/data/scripts/join_results.py\"\n\n        # We need to construct the bash command\n        # \"echo 'Starting Join...' && cp /mnt/disks/gcs/data/scripts/join_results.py . && python3 join_results.py ...\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 join_results.py \"\n            f\"--smiles {smi} \"\n            f\"--rdkit {rd} \"\n            f\"--txgemma {tx} \"\n            f\"--gnina {gn} \"\n            f\"--output {out} \"\n            f\"--batch_id {loop_id}\"\n        )\n\n        # Depending on template, we might need to wrap in /bin/bash -c\n        # If template command is [\"python3\", ...], we replace it with [\"/bin/bash\", \"-c\", cmd_str]\n\n        container['command'] = [\"/bin/bash\", \"-c\", cmd_str]\n        # Note: 'command' vs 'commands'. K8s uses 'command', Batch Spec 'commands'. \n        # Check carefully. The template uses 'commands'.\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"selection\":\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/joined_results.csv\"\n        out_sel = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        out_pool = f\"{base_gcs_path}/output/{loop_id}/selection/unlabeled_pool.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/select_active_learning.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 select_active_learning.py \"\n            f\"--input {inp} \"\n            f\"--output_selected {out_sel} \"\n            f\"--output_pool {out_pool} \"\n            f\"--top_n 100\"\n        )\n\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"mock_fep\":\n        # Input: Selected candidates\n        # Output: FEP results (we need to enforce this path in `mock_fep_batch.py` or assume it writes to stdout?)\n        # `mock_fep_batch.py` currently writes to `fep_results.csv` locally or arg?\n        # Let's inspect `mock_fep_batch.py` usage in Spec.\n        # Spec says: `python3 /tmp/mock_fep.py --input ...`\n        # We should add `--output ...` if supported, or rely on defaults.\n        # Let's force output path:\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        out = f\"{base_gcs_path}/output/{loop_id}/oracle/fep_results.csv\"\n\n        # Patch command to include output flag (assuming supported or we pipe it)\n        # `mock_fep_batch.py` logic check needed. Assuming we can pass it.\n        # If not, let's assume it writes to same dir as input?\n        # Safe bet: Explicit arg: `python3 mock_fep.py --input ... --output ...`\n\n        cmd_idx = 1\n        c = container['commands'][cmd_idx]\n        c = re.sub(r\"--input\\s+\\S+\", f\"--input {inp}\", c)\n        c += f\" --output {out}\" # Append output arg\n        container['commands'][cmd_idx] = c\n\n    elif mode == \"trainer\":\n        # Inputs:\n        # 1. Labeled Data (Oracle Output)\n        # 2. Unlabeled Pool (Selection Output)\n        labeled = f\"{base_gcs_path}/output/{loop_id}/oracle/fep_results.csv\"\n        pool = f\"{base_gcs_path}/output/{loop_id}/selection/unlabeled_pool.csv\"\n\n        # Outputs:\n        # 1. Model Artifact\n        # 2. Predictions\n        model_out = f\"{base_gcs_path}/output/{loop_id}/training/proxy_model.json\"\n        pred_out = f\"{base_gcs_path}/output/{loop_id}/training/proxy_predictions.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/train_xgboost.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 train_xgboost.py \"\n            f\"--train {labeled} \"\n            f\"--predict {pool} \"\n            f\"--output_model {model_out} \"\n            f\"--output_predictions {pred_out}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"elite_selector\":\n        # Input: Predictions\n        inp = f\"{base_gcs_path}/output/{loop_id}/training/proxy_predictions.csv\"\n        # Output: Elite Candidates\n        out = f\"{base_gcs_path}/output/{loop_id}/selection_v2/elite_candidates.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/select_elite.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 select_elite.py \"\n            f\"--predictions {inp} \"\n            f\"--output {out} \"\n            f\"--n_elite 40 --n_random 10\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"redocker\":\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection_v2/elite_candidates.csv\"\n        out_dir = f\"{base_gcs_path}/output/{loop_id}/training_data/sdfs\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/redock_batch.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 redock_batch.py \"\n            f\"--input {inp} \"\n            f\"--output_dir {out_dir}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"finetune_launcher\":\n        data_dir = f\"{base_gcs_path}/output/{loop_id}/training_data/sdfs\"\n        # Model output will be a new directory for next cycle\n        model_out_dir = f\"{base_gcs_path}/output/{loop_id}/models/finetuned\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/finetune_launcher.py\"\n\n        # Params for launcher\n        proj = \"gcda-apac-sc\"\n        reg = \"us-central1\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 finetune_launcher.py \"\n            f\"--project {proj} \"\n            f\"--region {reg} \"\n            f\"--training_data_dir {data_dir} \"\n            f\"--output_model_dir {model_out_dir}\"\n            f\"--output_model_dir {model_out_dir}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"mmpbsa_fep\":\n        # Input: Candidates from selection\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        # Output: Results directory (CSV created inside)\n        out = f\"{base_gcs_path}/output/{loop_id}/oracle\"\n\n        # Original: /usr/local/bin/run_mmpbsa.sh --run --id batch_${BATCH_TASK_INDEX}\n        # We need to inject runtime copying of scripts? \n        # Actually, let's keep it simple: Ensure spec mounts correct paths or we override commands.\n        # The spec `mmpbsa-test-job.json` has `cp .../fep_setup.py` hardcoded.\n        # For pipeline, we should assume scripts are in `scripts/` or `input/`.\n\n        # Let's construct a command that:\n        # 1. Copies `fep_setup.py` and `run_mmpbsa.sh` from `scripts/`? \n        #    Or assume they are baked in image? Current status: Baked in image BUT we hotfix them.\n        #    Safe bet: Copy from GCS location defined in `BASE_GCS_PATH`.\n\n        script_dir = f\"{base_gcs_path}/data/scripts/mmpbsa_shards\"\n\n        # Command construction\n        # Note: We need to preserve BATCH_TASK_INDEX env var usage\n        cmd_str = (\n            f\"cp {script_dir}/fep_setup.py /usr/local/bin/fep_setup.py && \"\n            f\"cp {script_dir}/run_mmpbsa.sh /usr/local/bin/run_mmpbsa.sh && \"\n            f\"chmod +x /usr/local/bin/run_mmpbsa.sh /usr/local/bin/fep_setup.py && \"\n            f\"export BATCH_TASK_INDEX=${{BATCH_TASK_INDEX}} && \"\n            f\"/usr/local/bin/run_mmpbsa.sh --run --id batch_${{BATCH_TASK_INDEX}}\"\n        )\n\n        # Update mounts to point to dynamic loop paths if needed?\n        # Actually, mmpbsa READS from `INPUT_DIR`.\n        # By default `INPUT_DIR` is `/mnt/disks/gcs/input`.\n        # We need to ensure that `selected_candidates.csv` is split into `batch_N.csv` there?\n        # OR `run_mmpbsa.sh` reads `batch_N.csv`.\n        # Pipeline Gap: Who splits `selected_candidates.csv` into `batch_0.csv`?\n        # Answer: `stage_mmpbsa_batch` component? Or `selection` step?\n        # Current workflow test used `stage_mmpbsa_test.py`.\n        # We need a `staging` step in pipeline or `selection` output split.\n        # For now, let's assume `selection` outputs a single file and we execute ONE big batch or `run_mmpbsa` handles splitting?\n        # No, `run_mmpbsa.sh` expects `${JOB_ID}.csv`.\n        # We will add a \"Stager\" component later. For integration, we define the hook here.\n\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    return json.dumps(spec)\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-patch-spec-11": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "patch_spec"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.15.2' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef patch_spec(\n    spec_json_str: str,\n    loop_id: str,\n    mode: str,\n    base_gcs_path: str\n) -> str:\n    import json\n    import re\n\n    spec = json.loads(spec_json_str)\n\n    # Helper to clean command string\n    def update_cmd(container, old, new):\n        cmds = container['commands']\n        # If commands is list of strings\n        for i, c in enumerate(cmds):\n            if old in c:\n                cmds[i] = c.replace(old, new)\n        # If it's a -c \"...\" structure (common in our specs)\n        if len(cmds) > 1 and cmds[0] == \"-c\": # bash -c ...\n             cmds[1] = cmds[1].replace(old, new)\n\n    task = spec['taskGroups'][0]['taskSpec']['runnables'][0]\n    container = task['container']\n\n    # --- Logic ---\n    if mode == \"pocket2mol\":\n        # Output: /output/{loop_id}/generation\n        new_out = f\"{base_gcs_path}/output/{loop_id}/generation\"\n        # Naive replace of common flag patterns\n        # We rely on the template having a known structure or placeholders would be better.\n        # Let's assume the template has specific flags we can regex sub.\n        cmd = container['commands'][2] # Assuming bash -c \"...\" is at index 2 or 1\n        # Fix: The templates usually have [\"/bin/bash\", \"-c\", \"python ...\"] or similar\n        # Let's handle the string content of the last arg\n        cmd_idx = -1\n        cmd_str = container['commands'][cmd_idx]\n\n        cmd_str = re.sub(r\"--outdir\\s+\\S+\", f\"--outdir {new_out}\", cmd_str)\n        cmd_str = re.sub(r\"num_samples: \\d+\", \"num_samples: 50\", cmd_str) # Fast test\n\n        container['commands'][cmd_idx] = cmd_str\n\n    elif mode == \"gnina\" or mode == \"txgemma\" or mode == \"rdkit\":\n        # Input: /output/{loop_id}/generation/SMILES.txt\n        inp_path = f\"{base_gcs_path}/output/{loop_id}/generation/SMILES.txt\"\n\n        cmd_idx = -1\n        cmd_str = container['commands'][cmd_idx]\n\n        if mode == \"txgemma\":\n             cmd_str = re.sub(r\"--input-file\\s+\\S+\", f\"--input-file {inp_path}\", cmd_str)\n        elif mode == \"rdkit\":\n             cmd_str = re.sub(r\"--input_csv\\s+\\S+\", f\"--input_csv {inp_path}\", cmd_str)\n        elif mode == \"gnina\":\n             # Gnina script is positional? Or flags? \n             # Looking at task spec: /usr/local/bin/run_gnina_docking.sh <input> <output>\n             # We just append/replace\n             parts = cmd_str.split()\n             # Finding the script call\n             if \"run_gnina_docking.sh\" in cmd_str:\n                 # Replace the arg after the script\n                 # This is brittle. Let's assume standard arg order from template.\n                 # Better: Use placeholders in template {{INPUT_Path}}\n                 pass\n\n        container['commands'][cmd_idx] = cmd_str\n\n    elif mode == \"joiner\":\n        # Inputs from generation and filters\n        smi = f\"{base_gcs_path}/output/{loop_id}/generation/SMILES.txt\"\n        rd = f\"{base_gcs_path}/input/{loop_id}/filters/rdkit_scores.csv\" \n        tx = f\"{base_gcs_path}/input/{loop_id}/filters/txgemma_results.csv\"\n        # Gnina is a directory\n        gn = f\"{base_gcs_path}/input/{loop_id}/filters/gnina_out\"\n        out = f\"{base_gcs_path}/output/{loop_id}/selection/joined_results.csv\"\n\n        # Command: Copy script -> Run\n        script_src = f\"{base_gcs_path}/data/scripts/join_results.py\"\n\n        # We need to construct the bash command\n        # \"echo 'Starting Join...' && cp /mnt/disks/gcs/data/scripts/join_results.py . && python3 join_results.py ...\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 join_results.py \"\n            f\"--smiles {smi} \"\n            f\"--rdkit {rd} \"\n            f\"--txgemma {tx} \"\n            f\"--gnina {gn} \"\n            f\"--output {out} \"\n            f\"--batch_id {loop_id}\"\n        )\n\n        # Depending on template, we might need to wrap in /bin/bash -c\n        # If template command is [\"python3\", ...], we replace it with [\"/bin/bash\", \"-c\", cmd_str]\n\n        container['command'] = [\"/bin/bash\", \"-c\", cmd_str]\n        # Note: 'command' vs 'commands'. K8s uses 'command', Batch Spec 'commands'. \n        # Check carefully. The template uses 'commands'.\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"selection\":\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/joined_results.csv\"\n        out_sel = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        out_pool = f\"{base_gcs_path}/output/{loop_id}/selection/unlabeled_pool.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/select_active_learning.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 select_active_learning.py \"\n            f\"--input {inp} \"\n            f\"--output_selected {out_sel} \"\n            f\"--output_pool {out_pool} \"\n            f\"--top_n 100\"\n        )\n\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"mock_fep\":\n        # Input: Selected candidates\n        # Output: FEP results (we need to enforce this path in `mock_fep_batch.py` or assume it writes to stdout?)\n        # `mock_fep_batch.py` currently writes to `fep_results.csv` locally or arg?\n        # Let's inspect `mock_fep_batch.py` usage in Spec.\n        # Spec says: `python3 /tmp/mock_fep.py --input ...`\n        # We should add `--output ...` if supported, or rely on defaults.\n        # Let's force output path:\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        out = f\"{base_gcs_path}/output/{loop_id}/oracle/fep_results.csv\"\n\n        # Patch command to include output flag (assuming supported or we pipe it)\n        # `mock_fep_batch.py` logic check needed. Assuming we can pass it.\n        # If not, let's assume it writes to same dir as input?\n        # Safe bet: Explicit arg: `python3 mock_fep.py --input ... --output ...`\n\n        cmd_idx = 1\n        c = container['commands'][cmd_idx]\n        c = re.sub(r\"--input\\s+\\S+\", f\"--input {inp}\", c)\n        c += f\" --output {out}\" # Append output arg\n        container['commands'][cmd_idx] = c\n\n    elif mode == \"trainer\":\n        # Inputs:\n        # 1. Labeled Data (Oracle Output)\n        # 2. Unlabeled Pool (Selection Output)\n        labeled = f\"{base_gcs_path}/output/{loop_id}/oracle/fep_results.csv\"\n        pool = f\"{base_gcs_path}/output/{loop_id}/selection/unlabeled_pool.csv\"\n\n        # Outputs:\n        # 1. Model Artifact\n        # 2. Predictions\n        model_out = f\"{base_gcs_path}/output/{loop_id}/training/proxy_model.json\"\n        pred_out = f\"{base_gcs_path}/output/{loop_id}/training/proxy_predictions.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/train_xgboost.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 train_xgboost.py \"\n            f\"--train {labeled} \"\n            f\"--predict {pool} \"\n            f\"--output_model {model_out} \"\n            f\"--output_predictions {pred_out}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"elite_selector\":\n        # Input: Predictions\n        inp = f\"{base_gcs_path}/output/{loop_id}/training/proxy_predictions.csv\"\n        # Output: Elite Candidates\n        out = f\"{base_gcs_path}/output/{loop_id}/selection_v2/elite_candidates.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/select_elite.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 select_elite.py \"\n            f\"--predictions {inp} \"\n            f\"--output {out} \"\n            f\"--n_elite 40 --n_random 10\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"redocker\":\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection_v2/elite_candidates.csv\"\n        out_dir = f\"{base_gcs_path}/output/{loop_id}/training_data/sdfs\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/redock_batch.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 redock_batch.py \"\n            f\"--input {inp} \"\n            f\"--output_dir {out_dir}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"finetune_launcher\":\n        data_dir = f\"{base_gcs_path}/output/{loop_id}/training_data/sdfs\"\n        # Model output will be a new directory for next cycle\n        model_out_dir = f\"{base_gcs_path}/output/{loop_id}/models/finetuned\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/finetune_launcher.py\"\n\n        # Params for launcher\n        proj = \"gcda-apac-sc\"\n        reg = \"us-central1\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 finetune_launcher.py \"\n            f\"--project {proj} \"\n            f\"--region {reg} \"\n            f\"--training_data_dir {data_dir} \"\n            f\"--output_model_dir {model_out_dir}\"\n            f\"--output_model_dir {model_out_dir}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"mmpbsa_fep\":\n        # Input: Candidates from selection\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        # Output: Results directory (CSV created inside)\n        out = f\"{base_gcs_path}/output/{loop_id}/oracle\"\n\n        # Original: /usr/local/bin/run_mmpbsa.sh --run --id batch_${BATCH_TASK_INDEX}\n        # We need to inject runtime copying of scripts? \n        # Actually, let's keep it simple: Ensure spec mounts correct paths or we override commands.\n        # The spec `mmpbsa-test-job.json` has `cp .../fep_setup.py` hardcoded.\n        # For pipeline, we should assume scripts are in `scripts/` or `input/`.\n\n        # Let's construct a command that:\n        # 1. Copies `fep_setup.py` and `run_mmpbsa.sh` from `scripts/`? \n        #    Or assume they are baked in image? Current status: Baked in image BUT we hotfix them.\n        #    Safe bet: Copy from GCS location defined in `BASE_GCS_PATH`.\n\n        script_dir = f\"{base_gcs_path}/data/scripts/mmpbsa_shards\"\n\n        # Command construction\n        # Note: We need to preserve BATCH_TASK_INDEX env var usage\n        cmd_str = (\n            f\"cp {script_dir}/fep_setup.py /usr/local/bin/fep_setup.py && \"\n            f\"cp {script_dir}/run_mmpbsa.sh /usr/local/bin/run_mmpbsa.sh && \"\n            f\"chmod +x /usr/local/bin/run_mmpbsa.sh /usr/local/bin/fep_setup.py && \"\n            f\"export BATCH_TASK_INDEX=${{BATCH_TASK_INDEX}} && \"\n            f\"/usr/local/bin/run_mmpbsa.sh --run --id batch_${{BATCH_TASK_INDEX}}\"\n        )\n\n        # Update mounts to point to dynamic loop paths if needed?\n        # Actually, mmpbsa READS from `INPUT_DIR`.\n        # By default `INPUT_DIR` is `/mnt/disks/gcs/input`.\n        # We need to ensure that `selected_candidates.csv` is split into `batch_N.csv` there?\n        # OR `run_mmpbsa.sh` reads `batch_N.csv`.\n        # Pipeline Gap: Who splits `selected_candidates.csv` into `batch_0.csv`?\n        # Answer: `stage_mmpbsa_batch` component? Or `selection` step?\n        # Current workflow test used `stage_mmpbsa_test.py`.\n        # We need a `staging` step in pipeline or `selection` output split.\n        # For now, let's assume `selection` outputs a single file and we execute ONE big batch or `run_mmpbsa` handles splitting?\n        # No, `run_mmpbsa.sh` expects `${JOB_ID}.csv`.\n        # We will add a \"Stager\" component later. For integration, we define the hook here.\n\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    return json.dumps(spec)\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-patch-spec-2": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "patch_spec"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.15.2' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef patch_spec(\n    spec_json_str: str,\n    loop_id: str,\n    mode: str,\n    base_gcs_path: str\n) -> str:\n    import json\n    import re\n\n    spec = json.loads(spec_json_str)\n\n    # Helper to clean command string\n    def update_cmd(container, old, new):\n        cmds = container['commands']\n        # If commands is list of strings\n        for i, c in enumerate(cmds):\n            if old in c:\n                cmds[i] = c.replace(old, new)\n        # If it's a -c \"...\" structure (common in our specs)\n        if len(cmds) > 1 and cmds[0] == \"-c\": # bash -c ...\n             cmds[1] = cmds[1].replace(old, new)\n\n    task = spec['taskGroups'][0]['taskSpec']['runnables'][0]\n    container = task['container']\n\n    # --- Logic ---\n    if mode == \"pocket2mol\":\n        # Output: /output/{loop_id}/generation\n        new_out = f\"{base_gcs_path}/output/{loop_id}/generation\"\n        # Naive replace of common flag patterns\n        # We rely on the template having a known structure or placeholders would be better.\n        # Let's assume the template has specific flags we can regex sub.\n        cmd = container['commands'][2] # Assuming bash -c \"...\" is at index 2 or 1\n        # Fix: The templates usually have [\"/bin/bash\", \"-c\", \"python ...\"] or similar\n        # Let's handle the string content of the last arg\n        cmd_idx = -1\n        cmd_str = container['commands'][cmd_idx]\n\n        cmd_str = re.sub(r\"--outdir\\s+\\S+\", f\"--outdir {new_out}\", cmd_str)\n        cmd_str = re.sub(r\"num_samples: \\d+\", \"num_samples: 50\", cmd_str) # Fast test\n\n        container['commands'][cmd_idx] = cmd_str\n\n    elif mode == \"gnina\" or mode == \"txgemma\" or mode == \"rdkit\":\n        # Input: /output/{loop_id}/generation/SMILES.txt\n        inp_path = f\"{base_gcs_path}/output/{loop_id}/generation/SMILES.txt\"\n\n        cmd_idx = -1\n        cmd_str = container['commands'][cmd_idx]\n\n        if mode == \"txgemma\":\n             cmd_str = re.sub(r\"--input-file\\s+\\S+\", f\"--input-file {inp_path}\", cmd_str)\n        elif mode == \"rdkit\":\n             cmd_str = re.sub(r\"--input_csv\\s+\\S+\", f\"--input_csv {inp_path}\", cmd_str)\n        elif mode == \"gnina\":\n             # Gnina script is positional? Or flags? \n             # Looking at task spec: /usr/local/bin/run_gnina_docking.sh <input> <output>\n             # We just append/replace\n             parts = cmd_str.split()\n             # Finding the script call\n             if \"run_gnina_docking.sh\" in cmd_str:\n                 # Replace the arg after the script\n                 # This is brittle. Let's assume standard arg order from template.\n                 # Better: Use placeholders in template {{INPUT_Path}}\n                 pass\n\n        container['commands'][cmd_idx] = cmd_str\n\n    elif mode == \"joiner\":\n        # Inputs from generation and filters\n        smi = f\"{base_gcs_path}/output/{loop_id}/generation/SMILES.txt\"\n        rd = f\"{base_gcs_path}/input/{loop_id}/filters/rdkit_scores.csv\" \n        tx = f\"{base_gcs_path}/input/{loop_id}/filters/txgemma_results.csv\"\n        # Gnina is a directory\n        gn = f\"{base_gcs_path}/input/{loop_id}/filters/gnina_out\"\n        out = f\"{base_gcs_path}/output/{loop_id}/selection/joined_results.csv\"\n\n        # Command: Copy script -> Run\n        script_src = f\"{base_gcs_path}/data/scripts/join_results.py\"\n\n        # We need to construct the bash command\n        # \"echo 'Starting Join...' && cp /mnt/disks/gcs/data/scripts/join_results.py . && python3 join_results.py ...\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 join_results.py \"\n            f\"--smiles {smi} \"\n            f\"--rdkit {rd} \"\n            f\"--txgemma {tx} \"\n            f\"--gnina {gn} \"\n            f\"--output {out} \"\n            f\"--batch_id {loop_id}\"\n        )\n\n        # Depending on template, we might need to wrap in /bin/bash -c\n        # If template command is [\"python3\", ...], we replace it with [\"/bin/bash\", \"-c\", cmd_str]\n\n        container['command'] = [\"/bin/bash\", \"-c\", cmd_str]\n        # Note: 'command' vs 'commands'. K8s uses 'command', Batch Spec 'commands'. \n        # Check carefully. The template uses 'commands'.\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"selection\":\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/joined_results.csv\"\n        out_sel = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        out_pool = f\"{base_gcs_path}/output/{loop_id}/selection/unlabeled_pool.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/select_active_learning.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 select_active_learning.py \"\n            f\"--input {inp} \"\n            f\"--output_selected {out_sel} \"\n            f\"--output_pool {out_pool} \"\n            f\"--top_n 100\"\n        )\n\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"mock_fep\":\n        # Input: Selected candidates\n        # Output: FEP results (we need to enforce this path in `mock_fep_batch.py` or assume it writes to stdout?)\n        # `mock_fep_batch.py` currently writes to `fep_results.csv` locally or arg?\n        # Let's inspect `mock_fep_batch.py` usage in Spec.\n        # Spec says: `python3 /tmp/mock_fep.py --input ...`\n        # We should add `--output ...` if supported, or rely on defaults.\n        # Let's force output path:\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        out = f\"{base_gcs_path}/output/{loop_id}/oracle/fep_results.csv\"\n\n        # Patch command to include output flag (assuming supported or we pipe it)\n        # `mock_fep_batch.py` logic check needed. Assuming we can pass it.\n        # If not, let's assume it writes to same dir as input?\n        # Safe bet: Explicit arg: `python3 mock_fep.py --input ... --output ...`\n\n        cmd_idx = 1\n        c = container['commands'][cmd_idx]\n        c = re.sub(r\"--input\\s+\\S+\", f\"--input {inp}\", c)\n        c += f\" --output {out}\" # Append output arg\n        container['commands'][cmd_idx] = c\n\n    elif mode == \"trainer\":\n        # Inputs:\n        # 1. Labeled Data (Oracle Output)\n        # 2. Unlabeled Pool (Selection Output)\n        labeled = f\"{base_gcs_path}/output/{loop_id}/oracle/fep_results.csv\"\n        pool = f\"{base_gcs_path}/output/{loop_id}/selection/unlabeled_pool.csv\"\n\n        # Outputs:\n        # 1. Model Artifact\n        # 2. Predictions\n        model_out = f\"{base_gcs_path}/output/{loop_id}/training/proxy_model.json\"\n        pred_out = f\"{base_gcs_path}/output/{loop_id}/training/proxy_predictions.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/train_xgboost.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 train_xgboost.py \"\n            f\"--train {labeled} \"\n            f\"--predict {pool} \"\n            f\"--output_model {model_out} \"\n            f\"--output_predictions {pred_out}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"elite_selector\":\n        # Input: Predictions\n        inp = f\"{base_gcs_path}/output/{loop_id}/training/proxy_predictions.csv\"\n        # Output: Elite Candidates\n        out = f\"{base_gcs_path}/output/{loop_id}/selection_v2/elite_candidates.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/select_elite.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 select_elite.py \"\n            f\"--predictions {inp} \"\n            f\"--output {out} \"\n            f\"--n_elite 40 --n_random 10\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"redocker\":\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection_v2/elite_candidates.csv\"\n        out_dir = f\"{base_gcs_path}/output/{loop_id}/training_data/sdfs\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/redock_batch.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 redock_batch.py \"\n            f\"--input {inp} \"\n            f\"--output_dir {out_dir}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"finetune_launcher\":\n        data_dir = f\"{base_gcs_path}/output/{loop_id}/training_data/sdfs\"\n        # Model output will be a new directory for next cycle\n        model_out_dir = f\"{base_gcs_path}/output/{loop_id}/models/finetuned\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/finetune_launcher.py\"\n\n        # Params for launcher\n        proj = \"gcda-apac-sc\"\n        reg = \"us-central1\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 finetune_launcher.py \"\n            f\"--project {proj} \"\n            f\"--region {reg} \"\n            f\"--training_data_dir {data_dir} \"\n            f\"--output_model_dir {model_out_dir}\"\n            f\"--output_model_dir {model_out_dir}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"mmpbsa_fep\":\n        # Input: Candidates from selection\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        # Output: Results directory (CSV created inside)\n        out = f\"{base_gcs_path}/output/{loop_id}/oracle\"\n\n        # Original: /usr/local/bin/run_mmpbsa.sh --run --id batch_${BATCH_TASK_INDEX}\n        # We need to inject runtime copying of scripts? \n        # Actually, let's keep it simple: Ensure spec mounts correct paths or we override commands.\n        # The spec `mmpbsa-test-job.json` has `cp .../fep_setup.py` hardcoded.\n        # For pipeline, we should assume scripts are in `scripts/` or `input/`.\n\n        # Let's construct a command that:\n        # 1. Copies `fep_setup.py` and `run_mmpbsa.sh` from `scripts/`? \n        #    Or assume they are baked in image? Current status: Baked in image BUT we hotfix them.\n        #    Safe bet: Copy from GCS location defined in `BASE_GCS_PATH`.\n\n        script_dir = f\"{base_gcs_path}/data/scripts/mmpbsa_shards\"\n\n        # Command construction\n        # Note: We need to preserve BATCH_TASK_INDEX env var usage\n        cmd_str = (\n            f\"cp {script_dir}/fep_setup.py /usr/local/bin/fep_setup.py && \"\n            f\"cp {script_dir}/run_mmpbsa.sh /usr/local/bin/run_mmpbsa.sh && \"\n            f\"chmod +x /usr/local/bin/run_mmpbsa.sh /usr/local/bin/fep_setup.py && \"\n            f\"export BATCH_TASK_INDEX=${{BATCH_TASK_INDEX}} && \"\n            f\"/usr/local/bin/run_mmpbsa.sh --run --id batch_${{BATCH_TASK_INDEX}}\"\n        )\n\n        # Update mounts to point to dynamic loop paths if needed?\n        # Actually, mmpbsa READS from `INPUT_DIR`.\n        # By default `INPUT_DIR` is `/mnt/disks/gcs/input`.\n        # We need to ensure that `selected_candidates.csv` is split into `batch_N.csv` there?\n        # OR `run_mmpbsa.sh` reads `batch_N.csv`.\n        # Pipeline Gap: Who splits `selected_candidates.csv` into `batch_0.csv`?\n        # Answer: `stage_mmpbsa_batch` component? Or `selection` step?\n        # Current workflow test used `stage_mmpbsa_test.py`.\n        # We need a `staging` step in pipeline or `selection` output split.\n        # For now, let's assume `selection` outputs a single file and we execute ONE big batch or `run_mmpbsa` handles splitting?\n        # No, `run_mmpbsa.sh` expects `${JOB_ID}.csv`.\n        # We will add a \"Stager\" component later. For integration, we define the hook here.\n\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    return json.dumps(spec)\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-patch-spec-3": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "patch_spec"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.15.2' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef patch_spec(\n    spec_json_str: str,\n    loop_id: str,\n    mode: str,\n    base_gcs_path: str\n) -> str:\n    import json\n    import re\n\n    spec = json.loads(spec_json_str)\n\n    # Helper to clean command string\n    def update_cmd(container, old, new):\n        cmds = container['commands']\n        # If commands is list of strings\n        for i, c in enumerate(cmds):\n            if old in c:\n                cmds[i] = c.replace(old, new)\n        # If it's a -c \"...\" structure (common in our specs)\n        if len(cmds) > 1 and cmds[0] == \"-c\": # bash -c ...\n             cmds[1] = cmds[1].replace(old, new)\n\n    task = spec['taskGroups'][0]['taskSpec']['runnables'][0]\n    container = task['container']\n\n    # --- Logic ---\n    if mode == \"pocket2mol\":\n        # Output: /output/{loop_id}/generation\n        new_out = f\"{base_gcs_path}/output/{loop_id}/generation\"\n        # Naive replace of common flag patterns\n        # We rely on the template having a known structure or placeholders would be better.\n        # Let's assume the template has specific flags we can regex sub.\n        cmd = container['commands'][2] # Assuming bash -c \"...\" is at index 2 or 1\n        # Fix: The templates usually have [\"/bin/bash\", \"-c\", \"python ...\"] or similar\n        # Let's handle the string content of the last arg\n        cmd_idx = -1\n        cmd_str = container['commands'][cmd_idx]\n\n        cmd_str = re.sub(r\"--outdir\\s+\\S+\", f\"--outdir {new_out}\", cmd_str)\n        cmd_str = re.sub(r\"num_samples: \\d+\", \"num_samples: 50\", cmd_str) # Fast test\n\n        container['commands'][cmd_idx] = cmd_str\n\n    elif mode == \"gnina\" or mode == \"txgemma\" or mode == \"rdkit\":\n        # Input: /output/{loop_id}/generation/SMILES.txt\n        inp_path = f\"{base_gcs_path}/output/{loop_id}/generation/SMILES.txt\"\n\n        cmd_idx = -1\n        cmd_str = container['commands'][cmd_idx]\n\n        if mode == \"txgemma\":\n             cmd_str = re.sub(r\"--input-file\\s+\\S+\", f\"--input-file {inp_path}\", cmd_str)\n        elif mode == \"rdkit\":\n             cmd_str = re.sub(r\"--input_csv\\s+\\S+\", f\"--input_csv {inp_path}\", cmd_str)\n        elif mode == \"gnina\":\n             # Gnina script is positional? Or flags? \n             # Looking at task spec: /usr/local/bin/run_gnina_docking.sh <input> <output>\n             # We just append/replace\n             parts = cmd_str.split()\n             # Finding the script call\n             if \"run_gnina_docking.sh\" in cmd_str:\n                 # Replace the arg after the script\n                 # This is brittle. Let's assume standard arg order from template.\n                 # Better: Use placeholders in template {{INPUT_Path}}\n                 pass\n\n        container['commands'][cmd_idx] = cmd_str\n\n    elif mode == \"joiner\":\n        # Inputs from generation and filters\n        smi = f\"{base_gcs_path}/output/{loop_id}/generation/SMILES.txt\"\n        rd = f\"{base_gcs_path}/input/{loop_id}/filters/rdkit_scores.csv\" \n        tx = f\"{base_gcs_path}/input/{loop_id}/filters/txgemma_results.csv\"\n        # Gnina is a directory\n        gn = f\"{base_gcs_path}/input/{loop_id}/filters/gnina_out\"\n        out = f\"{base_gcs_path}/output/{loop_id}/selection/joined_results.csv\"\n\n        # Command: Copy script -> Run\n        script_src = f\"{base_gcs_path}/data/scripts/join_results.py\"\n\n        # We need to construct the bash command\n        # \"echo 'Starting Join...' && cp /mnt/disks/gcs/data/scripts/join_results.py . && python3 join_results.py ...\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 join_results.py \"\n            f\"--smiles {smi} \"\n            f\"--rdkit {rd} \"\n            f\"--txgemma {tx} \"\n            f\"--gnina {gn} \"\n            f\"--output {out} \"\n            f\"--batch_id {loop_id}\"\n        )\n\n        # Depending on template, we might need to wrap in /bin/bash -c\n        # If template command is [\"python3\", ...], we replace it with [\"/bin/bash\", \"-c\", cmd_str]\n\n        container['command'] = [\"/bin/bash\", \"-c\", cmd_str]\n        # Note: 'command' vs 'commands'. K8s uses 'command', Batch Spec 'commands'. \n        # Check carefully. The template uses 'commands'.\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"selection\":\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/joined_results.csv\"\n        out_sel = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        out_pool = f\"{base_gcs_path}/output/{loop_id}/selection/unlabeled_pool.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/select_active_learning.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 select_active_learning.py \"\n            f\"--input {inp} \"\n            f\"--output_selected {out_sel} \"\n            f\"--output_pool {out_pool} \"\n            f\"--top_n 100\"\n        )\n\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"mock_fep\":\n        # Input: Selected candidates\n        # Output: FEP results (we need to enforce this path in `mock_fep_batch.py` or assume it writes to stdout?)\n        # `mock_fep_batch.py` currently writes to `fep_results.csv` locally or arg?\n        # Let's inspect `mock_fep_batch.py` usage in Spec.\n        # Spec says: `python3 /tmp/mock_fep.py --input ...`\n        # We should add `--output ...` if supported, or rely on defaults.\n        # Let's force output path:\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        out = f\"{base_gcs_path}/output/{loop_id}/oracle/fep_results.csv\"\n\n        # Patch command to include output flag (assuming supported or we pipe it)\n        # `mock_fep_batch.py` logic check needed. Assuming we can pass it.\n        # If not, let's assume it writes to same dir as input?\n        # Safe bet: Explicit arg: `python3 mock_fep.py --input ... --output ...`\n\n        cmd_idx = 1\n        c = container['commands'][cmd_idx]\n        c = re.sub(r\"--input\\s+\\S+\", f\"--input {inp}\", c)\n        c += f\" --output {out}\" # Append output arg\n        container['commands'][cmd_idx] = c\n\n    elif mode == \"trainer\":\n        # Inputs:\n        # 1. Labeled Data (Oracle Output)\n        # 2. Unlabeled Pool (Selection Output)\n        labeled = f\"{base_gcs_path}/output/{loop_id}/oracle/fep_results.csv\"\n        pool = f\"{base_gcs_path}/output/{loop_id}/selection/unlabeled_pool.csv\"\n\n        # Outputs:\n        # 1. Model Artifact\n        # 2. Predictions\n        model_out = f\"{base_gcs_path}/output/{loop_id}/training/proxy_model.json\"\n        pred_out = f\"{base_gcs_path}/output/{loop_id}/training/proxy_predictions.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/train_xgboost.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 train_xgboost.py \"\n            f\"--train {labeled} \"\n            f\"--predict {pool} \"\n            f\"--output_model {model_out} \"\n            f\"--output_predictions {pred_out}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"elite_selector\":\n        # Input: Predictions\n        inp = f\"{base_gcs_path}/output/{loop_id}/training/proxy_predictions.csv\"\n        # Output: Elite Candidates\n        out = f\"{base_gcs_path}/output/{loop_id}/selection_v2/elite_candidates.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/select_elite.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 select_elite.py \"\n            f\"--predictions {inp} \"\n            f\"--output {out} \"\n            f\"--n_elite 40 --n_random 10\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"redocker\":\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection_v2/elite_candidates.csv\"\n        out_dir = f\"{base_gcs_path}/output/{loop_id}/training_data/sdfs\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/redock_batch.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 redock_batch.py \"\n            f\"--input {inp} \"\n            f\"--output_dir {out_dir}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"finetune_launcher\":\n        data_dir = f\"{base_gcs_path}/output/{loop_id}/training_data/sdfs\"\n        # Model output will be a new directory for next cycle\n        model_out_dir = f\"{base_gcs_path}/output/{loop_id}/models/finetuned\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/finetune_launcher.py\"\n\n        # Params for launcher\n        proj = \"gcda-apac-sc\"\n        reg = \"us-central1\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 finetune_launcher.py \"\n            f\"--project {proj} \"\n            f\"--region {reg} \"\n            f\"--training_data_dir {data_dir} \"\n            f\"--output_model_dir {model_out_dir}\"\n            f\"--output_model_dir {model_out_dir}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"mmpbsa_fep\":\n        # Input: Candidates from selection\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        # Output: Results directory (CSV created inside)\n        out = f\"{base_gcs_path}/output/{loop_id}/oracle\"\n\n        # Original: /usr/local/bin/run_mmpbsa.sh --run --id batch_${BATCH_TASK_INDEX}\n        # We need to inject runtime copying of scripts? \n        # Actually, let's keep it simple: Ensure spec mounts correct paths or we override commands.\n        # The spec `mmpbsa-test-job.json` has `cp .../fep_setup.py` hardcoded.\n        # For pipeline, we should assume scripts are in `scripts/` or `input/`.\n\n        # Let's construct a command that:\n        # 1. Copies `fep_setup.py` and `run_mmpbsa.sh` from `scripts/`? \n        #    Or assume they are baked in image? Current status: Baked in image BUT we hotfix them.\n        #    Safe bet: Copy from GCS location defined in `BASE_GCS_PATH`.\n\n        script_dir = f\"{base_gcs_path}/data/scripts/mmpbsa_shards\"\n\n        # Command construction\n        # Note: We need to preserve BATCH_TASK_INDEX env var usage\n        cmd_str = (\n            f\"cp {script_dir}/fep_setup.py /usr/local/bin/fep_setup.py && \"\n            f\"cp {script_dir}/run_mmpbsa.sh /usr/local/bin/run_mmpbsa.sh && \"\n            f\"chmod +x /usr/local/bin/run_mmpbsa.sh /usr/local/bin/fep_setup.py && \"\n            f\"export BATCH_TASK_INDEX=${{BATCH_TASK_INDEX}} && \"\n            f\"/usr/local/bin/run_mmpbsa.sh --run --id batch_${{BATCH_TASK_INDEX}}\"\n        )\n\n        # Update mounts to point to dynamic loop paths if needed?\n        # Actually, mmpbsa READS from `INPUT_DIR`.\n        # By default `INPUT_DIR` is `/mnt/disks/gcs/input`.\n        # We need to ensure that `selected_candidates.csv` is split into `batch_N.csv` there?\n        # OR `run_mmpbsa.sh` reads `batch_N.csv`.\n        # Pipeline Gap: Who splits `selected_candidates.csv` into `batch_0.csv`?\n        # Answer: `stage_mmpbsa_batch` component? Or `selection` step?\n        # Current workflow test used `stage_mmpbsa_test.py`.\n        # We need a `staging` step in pipeline or `selection` output split.\n        # For now, let's assume `selection` outputs a single file and we execute ONE big batch or `run_mmpbsa` handles splitting?\n        # No, `run_mmpbsa.sh` expects `${JOB_ID}.csv`.\n        # We will add a \"Stager\" component later. For integration, we define the hook here.\n\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    return json.dumps(spec)\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-patch-spec-4": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "patch_spec"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.15.2' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef patch_spec(\n    spec_json_str: str,\n    loop_id: str,\n    mode: str,\n    base_gcs_path: str\n) -> str:\n    import json\n    import re\n\n    spec = json.loads(spec_json_str)\n\n    # Helper to clean command string\n    def update_cmd(container, old, new):\n        cmds = container['commands']\n        # If commands is list of strings\n        for i, c in enumerate(cmds):\n            if old in c:\n                cmds[i] = c.replace(old, new)\n        # If it's a -c \"...\" structure (common in our specs)\n        if len(cmds) > 1 and cmds[0] == \"-c\": # bash -c ...\n             cmds[1] = cmds[1].replace(old, new)\n\n    task = spec['taskGroups'][0]['taskSpec']['runnables'][0]\n    container = task['container']\n\n    # --- Logic ---\n    if mode == \"pocket2mol\":\n        # Output: /output/{loop_id}/generation\n        new_out = f\"{base_gcs_path}/output/{loop_id}/generation\"\n        # Naive replace of common flag patterns\n        # We rely on the template having a known structure or placeholders would be better.\n        # Let's assume the template has specific flags we can regex sub.\n        cmd = container['commands'][2] # Assuming bash -c \"...\" is at index 2 or 1\n        # Fix: The templates usually have [\"/bin/bash\", \"-c\", \"python ...\"] or similar\n        # Let's handle the string content of the last arg\n        cmd_idx = -1\n        cmd_str = container['commands'][cmd_idx]\n\n        cmd_str = re.sub(r\"--outdir\\s+\\S+\", f\"--outdir {new_out}\", cmd_str)\n        cmd_str = re.sub(r\"num_samples: \\d+\", \"num_samples: 50\", cmd_str) # Fast test\n\n        container['commands'][cmd_idx] = cmd_str\n\n    elif mode == \"gnina\" or mode == \"txgemma\" or mode == \"rdkit\":\n        # Input: /output/{loop_id}/generation/SMILES.txt\n        inp_path = f\"{base_gcs_path}/output/{loop_id}/generation/SMILES.txt\"\n\n        cmd_idx = -1\n        cmd_str = container['commands'][cmd_idx]\n\n        if mode == \"txgemma\":\n             cmd_str = re.sub(r\"--input-file\\s+\\S+\", f\"--input-file {inp_path}\", cmd_str)\n        elif mode == \"rdkit\":\n             cmd_str = re.sub(r\"--input_csv\\s+\\S+\", f\"--input_csv {inp_path}\", cmd_str)\n        elif mode == \"gnina\":\n             # Gnina script is positional? Or flags? \n             # Looking at task spec: /usr/local/bin/run_gnina_docking.sh <input> <output>\n             # We just append/replace\n             parts = cmd_str.split()\n             # Finding the script call\n             if \"run_gnina_docking.sh\" in cmd_str:\n                 # Replace the arg after the script\n                 # This is brittle. Let's assume standard arg order from template.\n                 # Better: Use placeholders in template {{INPUT_Path}}\n                 pass\n\n        container['commands'][cmd_idx] = cmd_str\n\n    elif mode == \"joiner\":\n        # Inputs from generation and filters\n        smi = f\"{base_gcs_path}/output/{loop_id}/generation/SMILES.txt\"\n        rd = f\"{base_gcs_path}/input/{loop_id}/filters/rdkit_scores.csv\" \n        tx = f\"{base_gcs_path}/input/{loop_id}/filters/txgemma_results.csv\"\n        # Gnina is a directory\n        gn = f\"{base_gcs_path}/input/{loop_id}/filters/gnina_out\"\n        out = f\"{base_gcs_path}/output/{loop_id}/selection/joined_results.csv\"\n\n        # Command: Copy script -> Run\n        script_src = f\"{base_gcs_path}/data/scripts/join_results.py\"\n\n        # We need to construct the bash command\n        # \"echo 'Starting Join...' && cp /mnt/disks/gcs/data/scripts/join_results.py . && python3 join_results.py ...\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 join_results.py \"\n            f\"--smiles {smi} \"\n            f\"--rdkit {rd} \"\n            f\"--txgemma {tx} \"\n            f\"--gnina {gn} \"\n            f\"--output {out} \"\n            f\"--batch_id {loop_id}\"\n        )\n\n        # Depending on template, we might need to wrap in /bin/bash -c\n        # If template command is [\"python3\", ...], we replace it with [\"/bin/bash\", \"-c\", cmd_str]\n\n        container['command'] = [\"/bin/bash\", \"-c\", cmd_str]\n        # Note: 'command' vs 'commands'. K8s uses 'command', Batch Spec 'commands'. \n        # Check carefully. The template uses 'commands'.\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"selection\":\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/joined_results.csv\"\n        out_sel = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        out_pool = f\"{base_gcs_path}/output/{loop_id}/selection/unlabeled_pool.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/select_active_learning.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 select_active_learning.py \"\n            f\"--input {inp} \"\n            f\"--output_selected {out_sel} \"\n            f\"--output_pool {out_pool} \"\n            f\"--top_n 100\"\n        )\n\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"mock_fep\":\n        # Input: Selected candidates\n        # Output: FEP results (we need to enforce this path in `mock_fep_batch.py` or assume it writes to stdout?)\n        # `mock_fep_batch.py` currently writes to `fep_results.csv` locally or arg?\n        # Let's inspect `mock_fep_batch.py` usage in Spec.\n        # Spec says: `python3 /tmp/mock_fep.py --input ...`\n        # We should add `--output ...` if supported, or rely on defaults.\n        # Let's force output path:\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        out = f\"{base_gcs_path}/output/{loop_id}/oracle/fep_results.csv\"\n\n        # Patch command to include output flag (assuming supported or we pipe it)\n        # `mock_fep_batch.py` logic check needed. Assuming we can pass it.\n        # If not, let's assume it writes to same dir as input?\n        # Safe bet: Explicit arg: `python3 mock_fep.py --input ... --output ...`\n\n        cmd_idx = 1\n        c = container['commands'][cmd_idx]\n        c = re.sub(r\"--input\\s+\\S+\", f\"--input {inp}\", c)\n        c += f\" --output {out}\" # Append output arg\n        container['commands'][cmd_idx] = c\n\n    elif mode == \"trainer\":\n        # Inputs:\n        # 1. Labeled Data (Oracle Output)\n        # 2. Unlabeled Pool (Selection Output)\n        labeled = f\"{base_gcs_path}/output/{loop_id}/oracle/fep_results.csv\"\n        pool = f\"{base_gcs_path}/output/{loop_id}/selection/unlabeled_pool.csv\"\n\n        # Outputs:\n        # 1. Model Artifact\n        # 2. Predictions\n        model_out = f\"{base_gcs_path}/output/{loop_id}/training/proxy_model.json\"\n        pred_out = f\"{base_gcs_path}/output/{loop_id}/training/proxy_predictions.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/train_xgboost.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 train_xgboost.py \"\n            f\"--train {labeled} \"\n            f\"--predict {pool} \"\n            f\"--output_model {model_out} \"\n            f\"--output_predictions {pred_out}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"elite_selector\":\n        # Input: Predictions\n        inp = f\"{base_gcs_path}/output/{loop_id}/training/proxy_predictions.csv\"\n        # Output: Elite Candidates\n        out = f\"{base_gcs_path}/output/{loop_id}/selection_v2/elite_candidates.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/select_elite.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 select_elite.py \"\n            f\"--predictions {inp} \"\n            f\"--output {out} \"\n            f\"--n_elite 40 --n_random 10\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"redocker\":\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection_v2/elite_candidates.csv\"\n        out_dir = f\"{base_gcs_path}/output/{loop_id}/training_data/sdfs\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/redock_batch.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 redock_batch.py \"\n            f\"--input {inp} \"\n            f\"--output_dir {out_dir}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"finetune_launcher\":\n        data_dir = f\"{base_gcs_path}/output/{loop_id}/training_data/sdfs\"\n        # Model output will be a new directory for next cycle\n        model_out_dir = f\"{base_gcs_path}/output/{loop_id}/models/finetuned\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/finetune_launcher.py\"\n\n        # Params for launcher\n        proj = \"gcda-apac-sc\"\n        reg = \"us-central1\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 finetune_launcher.py \"\n            f\"--project {proj} \"\n            f\"--region {reg} \"\n            f\"--training_data_dir {data_dir} \"\n            f\"--output_model_dir {model_out_dir}\"\n            f\"--output_model_dir {model_out_dir}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"mmpbsa_fep\":\n        # Input: Candidates from selection\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        # Output: Results directory (CSV created inside)\n        out = f\"{base_gcs_path}/output/{loop_id}/oracle\"\n\n        # Original: /usr/local/bin/run_mmpbsa.sh --run --id batch_${BATCH_TASK_INDEX}\n        # We need to inject runtime copying of scripts? \n        # Actually, let's keep it simple: Ensure spec mounts correct paths or we override commands.\n        # The spec `mmpbsa-test-job.json` has `cp .../fep_setup.py` hardcoded.\n        # For pipeline, we should assume scripts are in `scripts/` or `input/`.\n\n        # Let's construct a command that:\n        # 1. Copies `fep_setup.py` and `run_mmpbsa.sh` from `scripts/`? \n        #    Or assume they are baked in image? Current status: Baked in image BUT we hotfix them.\n        #    Safe bet: Copy from GCS location defined in `BASE_GCS_PATH`.\n\n        script_dir = f\"{base_gcs_path}/data/scripts/mmpbsa_shards\"\n\n        # Command construction\n        # Note: We need to preserve BATCH_TASK_INDEX env var usage\n        cmd_str = (\n            f\"cp {script_dir}/fep_setup.py /usr/local/bin/fep_setup.py && \"\n            f\"cp {script_dir}/run_mmpbsa.sh /usr/local/bin/run_mmpbsa.sh && \"\n            f\"chmod +x /usr/local/bin/run_mmpbsa.sh /usr/local/bin/fep_setup.py && \"\n            f\"export BATCH_TASK_INDEX=${{BATCH_TASK_INDEX}} && \"\n            f\"/usr/local/bin/run_mmpbsa.sh --run --id batch_${{BATCH_TASK_INDEX}}\"\n        )\n\n        # Update mounts to point to dynamic loop paths if needed?\n        # Actually, mmpbsa READS from `INPUT_DIR`.\n        # By default `INPUT_DIR` is `/mnt/disks/gcs/input`.\n        # We need to ensure that `selected_candidates.csv` is split into `batch_N.csv` there?\n        # OR `run_mmpbsa.sh` reads `batch_N.csv`.\n        # Pipeline Gap: Who splits `selected_candidates.csv` into `batch_0.csv`?\n        # Answer: `stage_mmpbsa_batch` component? Or `selection` step?\n        # Current workflow test used `stage_mmpbsa_test.py`.\n        # We need a `staging` step in pipeline or `selection` output split.\n        # For now, let's assume `selection` outputs a single file and we execute ONE big batch or `run_mmpbsa` handles splitting?\n        # No, `run_mmpbsa.sh` expects `${JOB_ID}.csv`.\n        # We will add a \"Stager\" component later. For integration, we define the hook here.\n\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    return json.dumps(spec)\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-patch-spec-5": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "patch_spec"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.15.2' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef patch_spec(\n    spec_json_str: str,\n    loop_id: str,\n    mode: str,\n    base_gcs_path: str\n) -> str:\n    import json\n    import re\n\n    spec = json.loads(spec_json_str)\n\n    # Helper to clean command string\n    def update_cmd(container, old, new):\n        cmds = container['commands']\n        # If commands is list of strings\n        for i, c in enumerate(cmds):\n            if old in c:\n                cmds[i] = c.replace(old, new)\n        # If it's a -c \"...\" structure (common in our specs)\n        if len(cmds) > 1 and cmds[0] == \"-c\": # bash -c ...\n             cmds[1] = cmds[1].replace(old, new)\n\n    task = spec['taskGroups'][0]['taskSpec']['runnables'][0]\n    container = task['container']\n\n    # --- Logic ---\n    if mode == \"pocket2mol\":\n        # Output: /output/{loop_id}/generation\n        new_out = f\"{base_gcs_path}/output/{loop_id}/generation\"\n        # Naive replace of common flag patterns\n        # We rely on the template having a known structure or placeholders would be better.\n        # Let's assume the template has specific flags we can regex sub.\n        cmd = container['commands'][2] # Assuming bash -c \"...\" is at index 2 or 1\n        # Fix: The templates usually have [\"/bin/bash\", \"-c\", \"python ...\"] or similar\n        # Let's handle the string content of the last arg\n        cmd_idx = -1\n        cmd_str = container['commands'][cmd_idx]\n\n        cmd_str = re.sub(r\"--outdir\\s+\\S+\", f\"--outdir {new_out}\", cmd_str)\n        cmd_str = re.sub(r\"num_samples: \\d+\", \"num_samples: 50\", cmd_str) # Fast test\n\n        container['commands'][cmd_idx] = cmd_str\n\n    elif mode == \"gnina\" or mode == \"txgemma\" or mode == \"rdkit\":\n        # Input: /output/{loop_id}/generation/SMILES.txt\n        inp_path = f\"{base_gcs_path}/output/{loop_id}/generation/SMILES.txt\"\n\n        cmd_idx = -1\n        cmd_str = container['commands'][cmd_idx]\n\n        if mode == \"txgemma\":\n             cmd_str = re.sub(r\"--input-file\\s+\\S+\", f\"--input-file {inp_path}\", cmd_str)\n        elif mode == \"rdkit\":\n             cmd_str = re.sub(r\"--input_csv\\s+\\S+\", f\"--input_csv {inp_path}\", cmd_str)\n        elif mode == \"gnina\":\n             # Gnina script is positional? Or flags? \n             # Looking at task spec: /usr/local/bin/run_gnina_docking.sh <input> <output>\n             # We just append/replace\n             parts = cmd_str.split()\n             # Finding the script call\n             if \"run_gnina_docking.sh\" in cmd_str:\n                 # Replace the arg after the script\n                 # This is brittle. Let's assume standard arg order from template.\n                 # Better: Use placeholders in template {{INPUT_Path}}\n                 pass\n\n        container['commands'][cmd_idx] = cmd_str\n\n    elif mode == \"joiner\":\n        # Inputs from generation and filters\n        smi = f\"{base_gcs_path}/output/{loop_id}/generation/SMILES.txt\"\n        rd = f\"{base_gcs_path}/input/{loop_id}/filters/rdkit_scores.csv\" \n        tx = f\"{base_gcs_path}/input/{loop_id}/filters/txgemma_results.csv\"\n        # Gnina is a directory\n        gn = f\"{base_gcs_path}/input/{loop_id}/filters/gnina_out\"\n        out = f\"{base_gcs_path}/output/{loop_id}/selection/joined_results.csv\"\n\n        # Command: Copy script -> Run\n        script_src = f\"{base_gcs_path}/data/scripts/join_results.py\"\n\n        # We need to construct the bash command\n        # \"echo 'Starting Join...' && cp /mnt/disks/gcs/data/scripts/join_results.py . && python3 join_results.py ...\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 join_results.py \"\n            f\"--smiles {smi} \"\n            f\"--rdkit {rd} \"\n            f\"--txgemma {tx} \"\n            f\"--gnina {gn} \"\n            f\"--output {out} \"\n            f\"--batch_id {loop_id}\"\n        )\n\n        # Depending on template, we might need to wrap in /bin/bash -c\n        # If template command is [\"python3\", ...], we replace it with [\"/bin/bash\", \"-c\", cmd_str]\n\n        container['command'] = [\"/bin/bash\", \"-c\", cmd_str]\n        # Note: 'command' vs 'commands'. K8s uses 'command', Batch Spec 'commands'. \n        # Check carefully. The template uses 'commands'.\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"selection\":\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/joined_results.csv\"\n        out_sel = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        out_pool = f\"{base_gcs_path}/output/{loop_id}/selection/unlabeled_pool.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/select_active_learning.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 select_active_learning.py \"\n            f\"--input {inp} \"\n            f\"--output_selected {out_sel} \"\n            f\"--output_pool {out_pool} \"\n            f\"--top_n 100\"\n        )\n\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"mock_fep\":\n        # Input: Selected candidates\n        # Output: FEP results (we need to enforce this path in `mock_fep_batch.py` or assume it writes to stdout?)\n        # `mock_fep_batch.py` currently writes to `fep_results.csv` locally or arg?\n        # Let's inspect `mock_fep_batch.py` usage in Spec.\n        # Spec says: `python3 /tmp/mock_fep.py --input ...`\n        # We should add `--output ...` if supported, or rely on defaults.\n        # Let's force output path:\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        out = f\"{base_gcs_path}/output/{loop_id}/oracle/fep_results.csv\"\n\n        # Patch command to include output flag (assuming supported or we pipe it)\n        # `mock_fep_batch.py` logic check needed. Assuming we can pass it.\n        # If not, let's assume it writes to same dir as input?\n        # Safe bet: Explicit arg: `python3 mock_fep.py --input ... --output ...`\n\n        cmd_idx = 1\n        c = container['commands'][cmd_idx]\n        c = re.sub(r\"--input\\s+\\S+\", f\"--input {inp}\", c)\n        c += f\" --output {out}\" # Append output arg\n        container['commands'][cmd_idx] = c\n\n    elif mode == \"trainer\":\n        # Inputs:\n        # 1. Labeled Data (Oracle Output)\n        # 2. Unlabeled Pool (Selection Output)\n        labeled = f\"{base_gcs_path}/output/{loop_id}/oracle/fep_results.csv\"\n        pool = f\"{base_gcs_path}/output/{loop_id}/selection/unlabeled_pool.csv\"\n\n        # Outputs:\n        # 1. Model Artifact\n        # 2. Predictions\n        model_out = f\"{base_gcs_path}/output/{loop_id}/training/proxy_model.json\"\n        pred_out = f\"{base_gcs_path}/output/{loop_id}/training/proxy_predictions.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/train_xgboost.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 train_xgboost.py \"\n            f\"--train {labeled} \"\n            f\"--predict {pool} \"\n            f\"--output_model {model_out} \"\n            f\"--output_predictions {pred_out}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"elite_selector\":\n        # Input: Predictions\n        inp = f\"{base_gcs_path}/output/{loop_id}/training/proxy_predictions.csv\"\n        # Output: Elite Candidates\n        out = f\"{base_gcs_path}/output/{loop_id}/selection_v2/elite_candidates.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/select_elite.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 select_elite.py \"\n            f\"--predictions {inp} \"\n            f\"--output {out} \"\n            f\"--n_elite 40 --n_random 10\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"redocker\":\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection_v2/elite_candidates.csv\"\n        out_dir = f\"{base_gcs_path}/output/{loop_id}/training_data/sdfs\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/redock_batch.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 redock_batch.py \"\n            f\"--input {inp} \"\n            f\"--output_dir {out_dir}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"finetune_launcher\":\n        data_dir = f\"{base_gcs_path}/output/{loop_id}/training_data/sdfs\"\n        # Model output will be a new directory for next cycle\n        model_out_dir = f\"{base_gcs_path}/output/{loop_id}/models/finetuned\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/finetune_launcher.py\"\n\n        # Params for launcher\n        proj = \"gcda-apac-sc\"\n        reg = \"us-central1\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 finetune_launcher.py \"\n            f\"--project {proj} \"\n            f\"--region {reg} \"\n            f\"--training_data_dir {data_dir} \"\n            f\"--output_model_dir {model_out_dir}\"\n            f\"--output_model_dir {model_out_dir}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"mmpbsa_fep\":\n        # Input: Candidates from selection\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        # Output: Results directory (CSV created inside)\n        out = f\"{base_gcs_path}/output/{loop_id}/oracle\"\n\n        # Original: /usr/local/bin/run_mmpbsa.sh --run --id batch_${BATCH_TASK_INDEX}\n        # We need to inject runtime copying of scripts? \n        # Actually, let's keep it simple: Ensure spec mounts correct paths or we override commands.\n        # The spec `mmpbsa-test-job.json` has `cp .../fep_setup.py` hardcoded.\n        # For pipeline, we should assume scripts are in `scripts/` or `input/`.\n\n        # Let's construct a command that:\n        # 1. Copies `fep_setup.py` and `run_mmpbsa.sh` from `scripts/`? \n        #    Or assume they are baked in image? Current status: Baked in image BUT we hotfix them.\n        #    Safe bet: Copy from GCS location defined in `BASE_GCS_PATH`.\n\n        script_dir = f\"{base_gcs_path}/data/scripts/mmpbsa_shards\"\n\n        # Command construction\n        # Note: We need to preserve BATCH_TASK_INDEX env var usage\n        cmd_str = (\n            f\"cp {script_dir}/fep_setup.py /usr/local/bin/fep_setup.py && \"\n            f\"cp {script_dir}/run_mmpbsa.sh /usr/local/bin/run_mmpbsa.sh && \"\n            f\"chmod +x /usr/local/bin/run_mmpbsa.sh /usr/local/bin/fep_setup.py && \"\n            f\"export BATCH_TASK_INDEX=${{BATCH_TASK_INDEX}} && \"\n            f\"/usr/local/bin/run_mmpbsa.sh --run --id batch_${{BATCH_TASK_INDEX}}\"\n        )\n\n        # Update mounts to point to dynamic loop paths if needed?\n        # Actually, mmpbsa READS from `INPUT_DIR`.\n        # By default `INPUT_DIR` is `/mnt/disks/gcs/input`.\n        # We need to ensure that `selected_candidates.csv` is split into `batch_N.csv` there?\n        # OR `run_mmpbsa.sh` reads `batch_N.csv`.\n        # Pipeline Gap: Who splits `selected_candidates.csv` into `batch_0.csv`?\n        # Answer: `stage_mmpbsa_batch` component? Or `selection` step?\n        # Current workflow test used `stage_mmpbsa_test.py`.\n        # We need a `staging` step in pipeline or `selection` output split.\n        # For now, let's assume `selection` outputs a single file and we execute ONE big batch or `run_mmpbsa` handles splitting?\n        # No, `run_mmpbsa.sh` expects `${JOB_ID}.csv`.\n        # We will add a \"Stager\" component later. For integration, we define the hook here.\n\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    return json.dumps(spec)\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-patch-spec-6": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "patch_spec"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.15.2' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef patch_spec(\n    spec_json_str: str,\n    loop_id: str,\n    mode: str,\n    base_gcs_path: str\n) -> str:\n    import json\n    import re\n\n    spec = json.loads(spec_json_str)\n\n    # Helper to clean command string\n    def update_cmd(container, old, new):\n        cmds = container['commands']\n        # If commands is list of strings\n        for i, c in enumerate(cmds):\n            if old in c:\n                cmds[i] = c.replace(old, new)\n        # If it's a -c \"...\" structure (common in our specs)\n        if len(cmds) > 1 and cmds[0] == \"-c\": # bash -c ...\n             cmds[1] = cmds[1].replace(old, new)\n\n    task = spec['taskGroups'][0]['taskSpec']['runnables'][0]\n    container = task['container']\n\n    # --- Logic ---\n    if mode == \"pocket2mol\":\n        # Output: /output/{loop_id}/generation\n        new_out = f\"{base_gcs_path}/output/{loop_id}/generation\"\n        # Naive replace of common flag patterns\n        # We rely on the template having a known structure or placeholders would be better.\n        # Let's assume the template has specific flags we can regex sub.\n        cmd = container['commands'][2] # Assuming bash -c \"...\" is at index 2 or 1\n        # Fix: The templates usually have [\"/bin/bash\", \"-c\", \"python ...\"] or similar\n        # Let's handle the string content of the last arg\n        cmd_idx = -1\n        cmd_str = container['commands'][cmd_idx]\n\n        cmd_str = re.sub(r\"--outdir\\s+\\S+\", f\"--outdir {new_out}\", cmd_str)\n        cmd_str = re.sub(r\"num_samples: \\d+\", \"num_samples: 50\", cmd_str) # Fast test\n\n        container['commands'][cmd_idx] = cmd_str\n\n    elif mode == \"gnina\" or mode == \"txgemma\" or mode == \"rdkit\":\n        # Input: /output/{loop_id}/generation/SMILES.txt\n        inp_path = f\"{base_gcs_path}/output/{loop_id}/generation/SMILES.txt\"\n\n        cmd_idx = -1\n        cmd_str = container['commands'][cmd_idx]\n\n        if mode == \"txgemma\":\n             cmd_str = re.sub(r\"--input-file\\s+\\S+\", f\"--input-file {inp_path}\", cmd_str)\n        elif mode == \"rdkit\":\n             cmd_str = re.sub(r\"--input_csv\\s+\\S+\", f\"--input_csv {inp_path}\", cmd_str)\n        elif mode == \"gnina\":\n             # Gnina script is positional? Or flags? \n             # Looking at task spec: /usr/local/bin/run_gnina_docking.sh <input> <output>\n             # We just append/replace\n             parts = cmd_str.split()\n             # Finding the script call\n             if \"run_gnina_docking.sh\" in cmd_str:\n                 # Replace the arg after the script\n                 # This is brittle. Let's assume standard arg order from template.\n                 # Better: Use placeholders in template {{INPUT_Path}}\n                 pass\n\n        container['commands'][cmd_idx] = cmd_str\n\n    elif mode == \"joiner\":\n        # Inputs from generation and filters\n        smi = f\"{base_gcs_path}/output/{loop_id}/generation/SMILES.txt\"\n        rd = f\"{base_gcs_path}/input/{loop_id}/filters/rdkit_scores.csv\" \n        tx = f\"{base_gcs_path}/input/{loop_id}/filters/txgemma_results.csv\"\n        # Gnina is a directory\n        gn = f\"{base_gcs_path}/input/{loop_id}/filters/gnina_out\"\n        out = f\"{base_gcs_path}/output/{loop_id}/selection/joined_results.csv\"\n\n        # Command: Copy script -> Run\n        script_src = f\"{base_gcs_path}/data/scripts/join_results.py\"\n\n        # We need to construct the bash command\n        # \"echo 'Starting Join...' && cp /mnt/disks/gcs/data/scripts/join_results.py . && python3 join_results.py ...\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 join_results.py \"\n            f\"--smiles {smi} \"\n            f\"--rdkit {rd} \"\n            f\"--txgemma {tx} \"\n            f\"--gnina {gn} \"\n            f\"--output {out} \"\n            f\"--batch_id {loop_id}\"\n        )\n\n        # Depending on template, we might need to wrap in /bin/bash -c\n        # If template command is [\"python3\", ...], we replace it with [\"/bin/bash\", \"-c\", cmd_str]\n\n        container['command'] = [\"/bin/bash\", \"-c\", cmd_str]\n        # Note: 'command' vs 'commands'. K8s uses 'command', Batch Spec 'commands'. \n        # Check carefully. The template uses 'commands'.\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"selection\":\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/joined_results.csv\"\n        out_sel = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        out_pool = f\"{base_gcs_path}/output/{loop_id}/selection/unlabeled_pool.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/select_active_learning.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 select_active_learning.py \"\n            f\"--input {inp} \"\n            f\"--output_selected {out_sel} \"\n            f\"--output_pool {out_pool} \"\n            f\"--top_n 100\"\n        )\n\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"mock_fep\":\n        # Input: Selected candidates\n        # Output: FEP results (we need to enforce this path in `mock_fep_batch.py` or assume it writes to stdout?)\n        # `mock_fep_batch.py` currently writes to `fep_results.csv` locally or arg?\n        # Let's inspect `mock_fep_batch.py` usage in Spec.\n        # Spec says: `python3 /tmp/mock_fep.py --input ...`\n        # We should add `--output ...` if supported, or rely on defaults.\n        # Let's force output path:\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        out = f\"{base_gcs_path}/output/{loop_id}/oracle/fep_results.csv\"\n\n        # Patch command to include output flag (assuming supported or we pipe it)\n        # `mock_fep_batch.py` logic check needed. Assuming we can pass it.\n        # If not, let's assume it writes to same dir as input?\n        # Safe bet: Explicit arg: `python3 mock_fep.py --input ... --output ...`\n\n        cmd_idx = 1\n        c = container['commands'][cmd_idx]\n        c = re.sub(r\"--input\\s+\\S+\", f\"--input {inp}\", c)\n        c += f\" --output {out}\" # Append output arg\n        container['commands'][cmd_idx] = c\n\n    elif mode == \"trainer\":\n        # Inputs:\n        # 1. Labeled Data (Oracle Output)\n        # 2. Unlabeled Pool (Selection Output)\n        labeled = f\"{base_gcs_path}/output/{loop_id}/oracle/fep_results.csv\"\n        pool = f\"{base_gcs_path}/output/{loop_id}/selection/unlabeled_pool.csv\"\n\n        # Outputs:\n        # 1. Model Artifact\n        # 2. Predictions\n        model_out = f\"{base_gcs_path}/output/{loop_id}/training/proxy_model.json\"\n        pred_out = f\"{base_gcs_path}/output/{loop_id}/training/proxy_predictions.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/train_xgboost.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 train_xgboost.py \"\n            f\"--train {labeled} \"\n            f\"--predict {pool} \"\n            f\"--output_model {model_out} \"\n            f\"--output_predictions {pred_out}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"elite_selector\":\n        # Input: Predictions\n        inp = f\"{base_gcs_path}/output/{loop_id}/training/proxy_predictions.csv\"\n        # Output: Elite Candidates\n        out = f\"{base_gcs_path}/output/{loop_id}/selection_v2/elite_candidates.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/select_elite.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 select_elite.py \"\n            f\"--predictions {inp} \"\n            f\"--output {out} \"\n            f\"--n_elite 40 --n_random 10\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"redocker\":\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection_v2/elite_candidates.csv\"\n        out_dir = f\"{base_gcs_path}/output/{loop_id}/training_data/sdfs\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/redock_batch.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 redock_batch.py \"\n            f\"--input {inp} \"\n            f\"--output_dir {out_dir}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"finetune_launcher\":\n        data_dir = f\"{base_gcs_path}/output/{loop_id}/training_data/sdfs\"\n        # Model output will be a new directory for next cycle\n        model_out_dir = f\"{base_gcs_path}/output/{loop_id}/models/finetuned\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/finetune_launcher.py\"\n\n        # Params for launcher\n        proj = \"gcda-apac-sc\"\n        reg = \"us-central1\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 finetune_launcher.py \"\n            f\"--project {proj} \"\n            f\"--region {reg} \"\n            f\"--training_data_dir {data_dir} \"\n            f\"--output_model_dir {model_out_dir}\"\n            f\"--output_model_dir {model_out_dir}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"mmpbsa_fep\":\n        # Input: Candidates from selection\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        # Output: Results directory (CSV created inside)\n        out = f\"{base_gcs_path}/output/{loop_id}/oracle\"\n\n        # Original: /usr/local/bin/run_mmpbsa.sh --run --id batch_${BATCH_TASK_INDEX}\n        # We need to inject runtime copying of scripts? \n        # Actually, let's keep it simple: Ensure spec mounts correct paths or we override commands.\n        # The spec `mmpbsa-test-job.json` has `cp .../fep_setup.py` hardcoded.\n        # For pipeline, we should assume scripts are in `scripts/` or `input/`.\n\n        # Let's construct a command that:\n        # 1. Copies `fep_setup.py` and `run_mmpbsa.sh` from `scripts/`? \n        #    Or assume they are baked in image? Current status: Baked in image BUT we hotfix them.\n        #    Safe bet: Copy from GCS location defined in `BASE_GCS_PATH`.\n\n        script_dir = f\"{base_gcs_path}/data/scripts/mmpbsa_shards\"\n\n        # Command construction\n        # Note: We need to preserve BATCH_TASK_INDEX env var usage\n        cmd_str = (\n            f\"cp {script_dir}/fep_setup.py /usr/local/bin/fep_setup.py && \"\n            f\"cp {script_dir}/run_mmpbsa.sh /usr/local/bin/run_mmpbsa.sh && \"\n            f\"chmod +x /usr/local/bin/run_mmpbsa.sh /usr/local/bin/fep_setup.py && \"\n            f\"export BATCH_TASK_INDEX=${{BATCH_TASK_INDEX}} && \"\n            f\"/usr/local/bin/run_mmpbsa.sh --run --id batch_${{BATCH_TASK_INDEX}}\"\n        )\n\n        # Update mounts to point to dynamic loop paths if needed?\n        # Actually, mmpbsa READS from `INPUT_DIR`.\n        # By default `INPUT_DIR` is `/mnt/disks/gcs/input`.\n        # We need to ensure that `selected_candidates.csv` is split into `batch_N.csv` there?\n        # OR `run_mmpbsa.sh` reads `batch_N.csv`.\n        # Pipeline Gap: Who splits `selected_candidates.csv` into `batch_0.csv`?\n        # Answer: `stage_mmpbsa_batch` component? Or `selection` step?\n        # Current workflow test used `stage_mmpbsa_test.py`.\n        # We need a `staging` step in pipeline or `selection` output split.\n        # For now, let's assume `selection` outputs a single file and we execute ONE big batch or `run_mmpbsa` handles splitting?\n        # No, `run_mmpbsa.sh` expects `${JOB_ID}.csv`.\n        # We will add a \"Stager\" component later. For integration, we define the hook here.\n\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    return json.dumps(spec)\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-patch-spec-7": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "patch_spec"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.15.2' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef patch_spec(\n    spec_json_str: str,\n    loop_id: str,\n    mode: str,\n    base_gcs_path: str\n) -> str:\n    import json\n    import re\n\n    spec = json.loads(spec_json_str)\n\n    # Helper to clean command string\n    def update_cmd(container, old, new):\n        cmds = container['commands']\n        # If commands is list of strings\n        for i, c in enumerate(cmds):\n            if old in c:\n                cmds[i] = c.replace(old, new)\n        # If it's a -c \"...\" structure (common in our specs)\n        if len(cmds) > 1 and cmds[0] == \"-c\": # bash -c ...\n             cmds[1] = cmds[1].replace(old, new)\n\n    task = spec['taskGroups'][0]['taskSpec']['runnables'][0]\n    container = task['container']\n\n    # --- Logic ---\n    if mode == \"pocket2mol\":\n        # Output: /output/{loop_id}/generation\n        new_out = f\"{base_gcs_path}/output/{loop_id}/generation\"\n        # Naive replace of common flag patterns\n        # We rely on the template having a known structure or placeholders would be better.\n        # Let's assume the template has specific flags we can regex sub.\n        cmd = container['commands'][2] # Assuming bash -c \"...\" is at index 2 or 1\n        # Fix: The templates usually have [\"/bin/bash\", \"-c\", \"python ...\"] or similar\n        # Let's handle the string content of the last arg\n        cmd_idx = -1\n        cmd_str = container['commands'][cmd_idx]\n\n        cmd_str = re.sub(r\"--outdir\\s+\\S+\", f\"--outdir {new_out}\", cmd_str)\n        cmd_str = re.sub(r\"num_samples: \\d+\", \"num_samples: 50\", cmd_str) # Fast test\n\n        container['commands'][cmd_idx] = cmd_str\n\n    elif mode == \"gnina\" or mode == \"txgemma\" or mode == \"rdkit\":\n        # Input: /output/{loop_id}/generation/SMILES.txt\n        inp_path = f\"{base_gcs_path}/output/{loop_id}/generation/SMILES.txt\"\n\n        cmd_idx = -1\n        cmd_str = container['commands'][cmd_idx]\n\n        if mode == \"txgemma\":\n             cmd_str = re.sub(r\"--input-file\\s+\\S+\", f\"--input-file {inp_path}\", cmd_str)\n        elif mode == \"rdkit\":\n             cmd_str = re.sub(r\"--input_csv\\s+\\S+\", f\"--input_csv {inp_path}\", cmd_str)\n        elif mode == \"gnina\":\n             # Gnina script is positional? Or flags? \n             # Looking at task spec: /usr/local/bin/run_gnina_docking.sh <input> <output>\n             # We just append/replace\n             parts = cmd_str.split()\n             # Finding the script call\n             if \"run_gnina_docking.sh\" in cmd_str:\n                 # Replace the arg after the script\n                 # This is brittle. Let's assume standard arg order from template.\n                 # Better: Use placeholders in template {{INPUT_Path}}\n                 pass\n\n        container['commands'][cmd_idx] = cmd_str\n\n    elif mode == \"joiner\":\n        # Inputs from generation and filters\n        smi = f\"{base_gcs_path}/output/{loop_id}/generation/SMILES.txt\"\n        rd = f\"{base_gcs_path}/input/{loop_id}/filters/rdkit_scores.csv\" \n        tx = f\"{base_gcs_path}/input/{loop_id}/filters/txgemma_results.csv\"\n        # Gnina is a directory\n        gn = f\"{base_gcs_path}/input/{loop_id}/filters/gnina_out\"\n        out = f\"{base_gcs_path}/output/{loop_id}/selection/joined_results.csv\"\n\n        # Command: Copy script -> Run\n        script_src = f\"{base_gcs_path}/data/scripts/join_results.py\"\n\n        # We need to construct the bash command\n        # \"echo 'Starting Join...' && cp /mnt/disks/gcs/data/scripts/join_results.py . && python3 join_results.py ...\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 join_results.py \"\n            f\"--smiles {smi} \"\n            f\"--rdkit {rd} \"\n            f\"--txgemma {tx} \"\n            f\"--gnina {gn} \"\n            f\"--output {out} \"\n            f\"--batch_id {loop_id}\"\n        )\n\n        # Depending on template, we might need to wrap in /bin/bash -c\n        # If template command is [\"python3\", ...], we replace it with [\"/bin/bash\", \"-c\", cmd_str]\n\n        container['command'] = [\"/bin/bash\", \"-c\", cmd_str]\n        # Note: 'command' vs 'commands'. K8s uses 'command', Batch Spec 'commands'. \n        # Check carefully. The template uses 'commands'.\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"selection\":\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/joined_results.csv\"\n        out_sel = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        out_pool = f\"{base_gcs_path}/output/{loop_id}/selection/unlabeled_pool.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/select_active_learning.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 select_active_learning.py \"\n            f\"--input {inp} \"\n            f\"--output_selected {out_sel} \"\n            f\"--output_pool {out_pool} \"\n            f\"--top_n 100\"\n        )\n\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"mock_fep\":\n        # Input: Selected candidates\n        # Output: FEP results (we need to enforce this path in `mock_fep_batch.py` or assume it writes to stdout?)\n        # `mock_fep_batch.py` currently writes to `fep_results.csv` locally or arg?\n        # Let's inspect `mock_fep_batch.py` usage in Spec.\n        # Spec says: `python3 /tmp/mock_fep.py --input ...`\n        # We should add `--output ...` if supported, or rely on defaults.\n        # Let's force output path:\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        out = f\"{base_gcs_path}/output/{loop_id}/oracle/fep_results.csv\"\n\n        # Patch command to include output flag (assuming supported or we pipe it)\n        # `mock_fep_batch.py` logic check needed. Assuming we can pass it.\n        # If not, let's assume it writes to same dir as input?\n        # Safe bet: Explicit arg: `python3 mock_fep.py --input ... --output ...`\n\n        cmd_idx = 1\n        c = container['commands'][cmd_idx]\n        c = re.sub(r\"--input\\s+\\S+\", f\"--input {inp}\", c)\n        c += f\" --output {out}\" # Append output arg\n        container['commands'][cmd_idx] = c\n\n    elif mode == \"trainer\":\n        # Inputs:\n        # 1. Labeled Data (Oracle Output)\n        # 2. Unlabeled Pool (Selection Output)\n        labeled = f\"{base_gcs_path}/output/{loop_id}/oracle/fep_results.csv\"\n        pool = f\"{base_gcs_path}/output/{loop_id}/selection/unlabeled_pool.csv\"\n\n        # Outputs:\n        # 1. Model Artifact\n        # 2. Predictions\n        model_out = f\"{base_gcs_path}/output/{loop_id}/training/proxy_model.json\"\n        pred_out = f\"{base_gcs_path}/output/{loop_id}/training/proxy_predictions.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/train_xgboost.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 train_xgboost.py \"\n            f\"--train {labeled} \"\n            f\"--predict {pool} \"\n            f\"--output_model {model_out} \"\n            f\"--output_predictions {pred_out}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"elite_selector\":\n        # Input: Predictions\n        inp = f\"{base_gcs_path}/output/{loop_id}/training/proxy_predictions.csv\"\n        # Output: Elite Candidates\n        out = f\"{base_gcs_path}/output/{loop_id}/selection_v2/elite_candidates.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/select_elite.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 select_elite.py \"\n            f\"--predictions {inp} \"\n            f\"--output {out} \"\n            f\"--n_elite 40 --n_random 10\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"redocker\":\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection_v2/elite_candidates.csv\"\n        out_dir = f\"{base_gcs_path}/output/{loop_id}/training_data/sdfs\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/redock_batch.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 redock_batch.py \"\n            f\"--input {inp} \"\n            f\"--output_dir {out_dir}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"finetune_launcher\":\n        data_dir = f\"{base_gcs_path}/output/{loop_id}/training_data/sdfs\"\n        # Model output will be a new directory for next cycle\n        model_out_dir = f\"{base_gcs_path}/output/{loop_id}/models/finetuned\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/finetune_launcher.py\"\n\n        # Params for launcher\n        proj = \"gcda-apac-sc\"\n        reg = \"us-central1\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 finetune_launcher.py \"\n            f\"--project {proj} \"\n            f\"--region {reg} \"\n            f\"--training_data_dir {data_dir} \"\n            f\"--output_model_dir {model_out_dir}\"\n            f\"--output_model_dir {model_out_dir}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"mmpbsa_fep\":\n        # Input: Candidates from selection\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        # Output: Results directory (CSV created inside)\n        out = f\"{base_gcs_path}/output/{loop_id}/oracle\"\n\n        # Original: /usr/local/bin/run_mmpbsa.sh --run --id batch_${BATCH_TASK_INDEX}\n        # We need to inject runtime copying of scripts? \n        # Actually, let's keep it simple: Ensure spec mounts correct paths or we override commands.\n        # The spec `mmpbsa-test-job.json` has `cp .../fep_setup.py` hardcoded.\n        # For pipeline, we should assume scripts are in `scripts/` or `input/`.\n\n        # Let's construct a command that:\n        # 1. Copies `fep_setup.py` and `run_mmpbsa.sh` from `scripts/`? \n        #    Or assume they are baked in image? Current status: Baked in image BUT we hotfix them.\n        #    Safe bet: Copy from GCS location defined in `BASE_GCS_PATH`.\n\n        script_dir = f\"{base_gcs_path}/data/scripts/mmpbsa_shards\"\n\n        # Command construction\n        # Note: We need to preserve BATCH_TASK_INDEX env var usage\n        cmd_str = (\n            f\"cp {script_dir}/fep_setup.py /usr/local/bin/fep_setup.py && \"\n            f\"cp {script_dir}/run_mmpbsa.sh /usr/local/bin/run_mmpbsa.sh && \"\n            f\"chmod +x /usr/local/bin/run_mmpbsa.sh /usr/local/bin/fep_setup.py && \"\n            f\"export BATCH_TASK_INDEX=${{BATCH_TASK_INDEX}} && \"\n            f\"/usr/local/bin/run_mmpbsa.sh --run --id batch_${{BATCH_TASK_INDEX}}\"\n        )\n\n        # Update mounts to point to dynamic loop paths if needed?\n        # Actually, mmpbsa READS from `INPUT_DIR`.\n        # By default `INPUT_DIR` is `/mnt/disks/gcs/input`.\n        # We need to ensure that `selected_candidates.csv` is split into `batch_N.csv` there?\n        # OR `run_mmpbsa.sh` reads `batch_N.csv`.\n        # Pipeline Gap: Who splits `selected_candidates.csv` into `batch_0.csv`?\n        # Answer: `stage_mmpbsa_batch` component? Or `selection` step?\n        # Current workflow test used `stage_mmpbsa_test.py`.\n        # We need a `staging` step in pipeline or `selection` output split.\n        # For now, let's assume `selection` outputs a single file and we execute ONE big batch or `run_mmpbsa` handles splitting?\n        # No, `run_mmpbsa.sh` expects `${JOB_ID}.csv`.\n        # We will add a \"Stager\" component later. For integration, we define the hook here.\n\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    return json.dumps(spec)\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-patch-spec-8": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "patch_spec"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.15.2' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef patch_spec(\n    spec_json_str: str,\n    loop_id: str,\n    mode: str,\n    base_gcs_path: str\n) -> str:\n    import json\n    import re\n\n    spec = json.loads(spec_json_str)\n\n    # Helper to clean command string\n    def update_cmd(container, old, new):\n        cmds = container['commands']\n        # If commands is list of strings\n        for i, c in enumerate(cmds):\n            if old in c:\n                cmds[i] = c.replace(old, new)\n        # If it's a -c \"...\" structure (common in our specs)\n        if len(cmds) > 1 and cmds[0] == \"-c\": # bash -c ...\n             cmds[1] = cmds[1].replace(old, new)\n\n    task = spec['taskGroups'][0]['taskSpec']['runnables'][0]\n    container = task['container']\n\n    # --- Logic ---\n    if mode == \"pocket2mol\":\n        # Output: /output/{loop_id}/generation\n        new_out = f\"{base_gcs_path}/output/{loop_id}/generation\"\n        # Naive replace of common flag patterns\n        # We rely on the template having a known structure or placeholders would be better.\n        # Let's assume the template has specific flags we can regex sub.\n        cmd = container['commands'][2] # Assuming bash -c \"...\" is at index 2 or 1\n        # Fix: The templates usually have [\"/bin/bash\", \"-c\", \"python ...\"] or similar\n        # Let's handle the string content of the last arg\n        cmd_idx = -1\n        cmd_str = container['commands'][cmd_idx]\n\n        cmd_str = re.sub(r\"--outdir\\s+\\S+\", f\"--outdir {new_out}\", cmd_str)\n        cmd_str = re.sub(r\"num_samples: \\d+\", \"num_samples: 50\", cmd_str) # Fast test\n\n        container['commands'][cmd_idx] = cmd_str\n\n    elif mode == \"gnina\" or mode == \"txgemma\" or mode == \"rdkit\":\n        # Input: /output/{loop_id}/generation/SMILES.txt\n        inp_path = f\"{base_gcs_path}/output/{loop_id}/generation/SMILES.txt\"\n\n        cmd_idx = -1\n        cmd_str = container['commands'][cmd_idx]\n\n        if mode == \"txgemma\":\n             cmd_str = re.sub(r\"--input-file\\s+\\S+\", f\"--input-file {inp_path}\", cmd_str)\n        elif mode == \"rdkit\":\n             cmd_str = re.sub(r\"--input_csv\\s+\\S+\", f\"--input_csv {inp_path}\", cmd_str)\n        elif mode == \"gnina\":\n             # Gnina script is positional? Or flags? \n             # Looking at task spec: /usr/local/bin/run_gnina_docking.sh <input> <output>\n             # We just append/replace\n             parts = cmd_str.split()\n             # Finding the script call\n             if \"run_gnina_docking.sh\" in cmd_str:\n                 # Replace the arg after the script\n                 # This is brittle. Let's assume standard arg order from template.\n                 # Better: Use placeholders in template {{INPUT_Path}}\n                 pass\n\n        container['commands'][cmd_idx] = cmd_str\n\n    elif mode == \"joiner\":\n        # Inputs from generation and filters\n        smi = f\"{base_gcs_path}/output/{loop_id}/generation/SMILES.txt\"\n        rd = f\"{base_gcs_path}/input/{loop_id}/filters/rdkit_scores.csv\" \n        tx = f\"{base_gcs_path}/input/{loop_id}/filters/txgemma_results.csv\"\n        # Gnina is a directory\n        gn = f\"{base_gcs_path}/input/{loop_id}/filters/gnina_out\"\n        out = f\"{base_gcs_path}/output/{loop_id}/selection/joined_results.csv\"\n\n        # Command: Copy script -> Run\n        script_src = f\"{base_gcs_path}/data/scripts/join_results.py\"\n\n        # We need to construct the bash command\n        # \"echo 'Starting Join...' && cp /mnt/disks/gcs/data/scripts/join_results.py . && python3 join_results.py ...\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 join_results.py \"\n            f\"--smiles {smi} \"\n            f\"--rdkit {rd} \"\n            f\"--txgemma {tx} \"\n            f\"--gnina {gn} \"\n            f\"--output {out} \"\n            f\"--batch_id {loop_id}\"\n        )\n\n        # Depending on template, we might need to wrap in /bin/bash -c\n        # If template command is [\"python3\", ...], we replace it with [\"/bin/bash\", \"-c\", cmd_str]\n\n        container['command'] = [\"/bin/bash\", \"-c\", cmd_str]\n        # Note: 'command' vs 'commands'. K8s uses 'command', Batch Spec 'commands'. \n        # Check carefully. The template uses 'commands'.\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"selection\":\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/joined_results.csv\"\n        out_sel = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        out_pool = f\"{base_gcs_path}/output/{loop_id}/selection/unlabeled_pool.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/select_active_learning.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 select_active_learning.py \"\n            f\"--input {inp} \"\n            f\"--output_selected {out_sel} \"\n            f\"--output_pool {out_pool} \"\n            f\"--top_n 100\"\n        )\n\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"mock_fep\":\n        # Input: Selected candidates\n        # Output: FEP results (we need to enforce this path in `mock_fep_batch.py` or assume it writes to stdout?)\n        # `mock_fep_batch.py` currently writes to `fep_results.csv` locally or arg?\n        # Let's inspect `mock_fep_batch.py` usage in Spec.\n        # Spec says: `python3 /tmp/mock_fep.py --input ...`\n        # We should add `--output ...` if supported, or rely on defaults.\n        # Let's force output path:\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        out = f\"{base_gcs_path}/output/{loop_id}/oracle/fep_results.csv\"\n\n        # Patch command to include output flag (assuming supported or we pipe it)\n        # `mock_fep_batch.py` logic check needed. Assuming we can pass it.\n        # If not, let's assume it writes to same dir as input?\n        # Safe bet: Explicit arg: `python3 mock_fep.py --input ... --output ...`\n\n        cmd_idx = 1\n        c = container['commands'][cmd_idx]\n        c = re.sub(r\"--input\\s+\\S+\", f\"--input {inp}\", c)\n        c += f\" --output {out}\" # Append output arg\n        container['commands'][cmd_idx] = c\n\n    elif mode == \"trainer\":\n        # Inputs:\n        # 1. Labeled Data (Oracle Output)\n        # 2. Unlabeled Pool (Selection Output)\n        labeled = f\"{base_gcs_path}/output/{loop_id}/oracle/fep_results.csv\"\n        pool = f\"{base_gcs_path}/output/{loop_id}/selection/unlabeled_pool.csv\"\n\n        # Outputs:\n        # 1. Model Artifact\n        # 2. Predictions\n        model_out = f\"{base_gcs_path}/output/{loop_id}/training/proxy_model.json\"\n        pred_out = f\"{base_gcs_path}/output/{loop_id}/training/proxy_predictions.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/train_xgboost.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 train_xgboost.py \"\n            f\"--train {labeled} \"\n            f\"--predict {pool} \"\n            f\"--output_model {model_out} \"\n            f\"--output_predictions {pred_out}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"elite_selector\":\n        # Input: Predictions\n        inp = f\"{base_gcs_path}/output/{loop_id}/training/proxy_predictions.csv\"\n        # Output: Elite Candidates\n        out = f\"{base_gcs_path}/output/{loop_id}/selection_v2/elite_candidates.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/select_elite.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 select_elite.py \"\n            f\"--predictions {inp} \"\n            f\"--output {out} \"\n            f\"--n_elite 40 --n_random 10\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"redocker\":\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection_v2/elite_candidates.csv\"\n        out_dir = f\"{base_gcs_path}/output/{loop_id}/training_data/sdfs\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/redock_batch.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 redock_batch.py \"\n            f\"--input {inp} \"\n            f\"--output_dir {out_dir}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"finetune_launcher\":\n        data_dir = f\"{base_gcs_path}/output/{loop_id}/training_data/sdfs\"\n        # Model output will be a new directory for next cycle\n        model_out_dir = f\"{base_gcs_path}/output/{loop_id}/models/finetuned\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/finetune_launcher.py\"\n\n        # Params for launcher\n        proj = \"gcda-apac-sc\"\n        reg = \"us-central1\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 finetune_launcher.py \"\n            f\"--project {proj} \"\n            f\"--region {reg} \"\n            f\"--training_data_dir {data_dir} \"\n            f\"--output_model_dir {model_out_dir}\"\n            f\"--output_model_dir {model_out_dir}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"mmpbsa_fep\":\n        # Input: Candidates from selection\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        # Output: Results directory (CSV created inside)\n        out = f\"{base_gcs_path}/output/{loop_id}/oracle\"\n\n        # Original: /usr/local/bin/run_mmpbsa.sh --run --id batch_${BATCH_TASK_INDEX}\n        # We need to inject runtime copying of scripts? \n        # Actually, let's keep it simple: Ensure spec mounts correct paths or we override commands.\n        # The spec `mmpbsa-test-job.json` has `cp .../fep_setup.py` hardcoded.\n        # For pipeline, we should assume scripts are in `scripts/` or `input/`.\n\n        # Let's construct a command that:\n        # 1. Copies `fep_setup.py` and `run_mmpbsa.sh` from `scripts/`? \n        #    Or assume they are baked in image? Current status: Baked in image BUT we hotfix them.\n        #    Safe bet: Copy from GCS location defined in `BASE_GCS_PATH`.\n\n        script_dir = f\"{base_gcs_path}/data/scripts/mmpbsa_shards\"\n\n        # Command construction\n        # Note: We need to preserve BATCH_TASK_INDEX env var usage\n        cmd_str = (\n            f\"cp {script_dir}/fep_setup.py /usr/local/bin/fep_setup.py && \"\n            f\"cp {script_dir}/run_mmpbsa.sh /usr/local/bin/run_mmpbsa.sh && \"\n            f\"chmod +x /usr/local/bin/run_mmpbsa.sh /usr/local/bin/fep_setup.py && \"\n            f\"export BATCH_TASK_INDEX=${{BATCH_TASK_INDEX}} && \"\n            f\"/usr/local/bin/run_mmpbsa.sh --run --id batch_${{BATCH_TASK_INDEX}}\"\n        )\n\n        # Update mounts to point to dynamic loop paths if needed?\n        # Actually, mmpbsa READS from `INPUT_DIR`.\n        # By default `INPUT_DIR` is `/mnt/disks/gcs/input`.\n        # We need to ensure that `selected_candidates.csv` is split into `batch_N.csv` there?\n        # OR `run_mmpbsa.sh` reads `batch_N.csv`.\n        # Pipeline Gap: Who splits `selected_candidates.csv` into `batch_0.csv`?\n        # Answer: `stage_mmpbsa_batch` component? Or `selection` step?\n        # Current workflow test used `stage_mmpbsa_test.py`.\n        # We need a `staging` step in pipeline or `selection` output split.\n        # For now, let's assume `selection` outputs a single file and we execute ONE big batch or `run_mmpbsa` handles splitting?\n        # No, `run_mmpbsa.sh` expects `${JOB_ID}.csv`.\n        # We will add a \"Stager\" component later. For integration, we define the hook here.\n\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    return json.dumps(spec)\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-patch-spec-9": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "patch_spec"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.15.2' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef patch_spec(\n    spec_json_str: str,\n    loop_id: str,\n    mode: str,\n    base_gcs_path: str\n) -> str:\n    import json\n    import re\n\n    spec = json.loads(spec_json_str)\n\n    # Helper to clean command string\n    def update_cmd(container, old, new):\n        cmds = container['commands']\n        # If commands is list of strings\n        for i, c in enumerate(cmds):\n            if old in c:\n                cmds[i] = c.replace(old, new)\n        # If it's a -c \"...\" structure (common in our specs)\n        if len(cmds) > 1 and cmds[0] == \"-c\": # bash -c ...\n             cmds[1] = cmds[1].replace(old, new)\n\n    task = spec['taskGroups'][0]['taskSpec']['runnables'][0]\n    container = task['container']\n\n    # --- Logic ---\n    if mode == \"pocket2mol\":\n        # Output: /output/{loop_id}/generation\n        new_out = f\"{base_gcs_path}/output/{loop_id}/generation\"\n        # Naive replace of common flag patterns\n        # We rely on the template having a known structure or placeholders would be better.\n        # Let's assume the template has specific flags we can regex sub.\n        cmd = container['commands'][2] # Assuming bash -c \"...\" is at index 2 or 1\n        # Fix: The templates usually have [\"/bin/bash\", \"-c\", \"python ...\"] or similar\n        # Let's handle the string content of the last arg\n        cmd_idx = -1\n        cmd_str = container['commands'][cmd_idx]\n\n        cmd_str = re.sub(r\"--outdir\\s+\\S+\", f\"--outdir {new_out}\", cmd_str)\n        cmd_str = re.sub(r\"num_samples: \\d+\", \"num_samples: 50\", cmd_str) # Fast test\n\n        container['commands'][cmd_idx] = cmd_str\n\n    elif mode == \"gnina\" or mode == \"txgemma\" or mode == \"rdkit\":\n        # Input: /output/{loop_id}/generation/SMILES.txt\n        inp_path = f\"{base_gcs_path}/output/{loop_id}/generation/SMILES.txt\"\n\n        cmd_idx = -1\n        cmd_str = container['commands'][cmd_idx]\n\n        if mode == \"txgemma\":\n             cmd_str = re.sub(r\"--input-file\\s+\\S+\", f\"--input-file {inp_path}\", cmd_str)\n        elif mode == \"rdkit\":\n             cmd_str = re.sub(r\"--input_csv\\s+\\S+\", f\"--input_csv {inp_path}\", cmd_str)\n        elif mode == \"gnina\":\n             # Gnina script is positional? Or flags? \n             # Looking at task spec: /usr/local/bin/run_gnina_docking.sh <input> <output>\n             # We just append/replace\n             parts = cmd_str.split()\n             # Finding the script call\n             if \"run_gnina_docking.sh\" in cmd_str:\n                 # Replace the arg after the script\n                 # This is brittle. Let's assume standard arg order from template.\n                 # Better: Use placeholders in template {{INPUT_Path}}\n                 pass\n\n        container['commands'][cmd_idx] = cmd_str\n\n    elif mode == \"joiner\":\n        # Inputs from generation and filters\n        smi = f\"{base_gcs_path}/output/{loop_id}/generation/SMILES.txt\"\n        rd = f\"{base_gcs_path}/input/{loop_id}/filters/rdkit_scores.csv\" \n        tx = f\"{base_gcs_path}/input/{loop_id}/filters/txgemma_results.csv\"\n        # Gnina is a directory\n        gn = f\"{base_gcs_path}/input/{loop_id}/filters/gnina_out\"\n        out = f\"{base_gcs_path}/output/{loop_id}/selection/joined_results.csv\"\n\n        # Command: Copy script -> Run\n        script_src = f\"{base_gcs_path}/data/scripts/join_results.py\"\n\n        # We need to construct the bash command\n        # \"echo 'Starting Join...' && cp /mnt/disks/gcs/data/scripts/join_results.py . && python3 join_results.py ...\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 join_results.py \"\n            f\"--smiles {smi} \"\n            f\"--rdkit {rd} \"\n            f\"--txgemma {tx} \"\n            f\"--gnina {gn} \"\n            f\"--output {out} \"\n            f\"--batch_id {loop_id}\"\n        )\n\n        # Depending on template, we might need to wrap in /bin/bash -c\n        # If template command is [\"python3\", ...], we replace it with [\"/bin/bash\", \"-c\", cmd_str]\n\n        container['command'] = [\"/bin/bash\", \"-c\", cmd_str]\n        # Note: 'command' vs 'commands'. K8s uses 'command', Batch Spec 'commands'. \n        # Check carefully. The template uses 'commands'.\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"selection\":\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/joined_results.csv\"\n        out_sel = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        out_pool = f\"{base_gcs_path}/output/{loop_id}/selection/unlabeled_pool.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/select_active_learning.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 select_active_learning.py \"\n            f\"--input {inp} \"\n            f\"--output_selected {out_sel} \"\n            f\"--output_pool {out_pool} \"\n            f\"--top_n 100\"\n        )\n\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"mock_fep\":\n        # Input: Selected candidates\n        # Output: FEP results (we need to enforce this path in `mock_fep_batch.py` or assume it writes to stdout?)\n        # `mock_fep_batch.py` currently writes to `fep_results.csv` locally or arg?\n        # Let's inspect `mock_fep_batch.py` usage in Spec.\n        # Spec says: `python3 /tmp/mock_fep.py --input ...`\n        # We should add `--output ...` if supported, or rely on defaults.\n        # Let's force output path:\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        out = f\"{base_gcs_path}/output/{loop_id}/oracle/fep_results.csv\"\n\n        # Patch command to include output flag (assuming supported or we pipe it)\n        # `mock_fep_batch.py` logic check needed. Assuming we can pass it.\n        # If not, let's assume it writes to same dir as input?\n        # Safe bet: Explicit arg: `python3 mock_fep.py --input ... --output ...`\n\n        cmd_idx = 1\n        c = container['commands'][cmd_idx]\n        c = re.sub(r\"--input\\s+\\S+\", f\"--input {inp}\", c)\n        c += f\" --output {out}\" # Append output arg\n        container['commands'][cmd_idx] = c\n\n    elif mode == \"trainer\":\n        # Inputs:\n        # 1. Labeled Data (Oracle Output)\n        # 2. Unlabeled Pool (Selection Output)\n        labeled = f\"{base_gcs_path}/output/{loop_id}/oracle/fep_results.csv\"\n        pool = f\"{base_gcs_path}/output/{loop_id}/selection/unlabeled_pool.csv\"\n\n        # Outputs:\n        # 1. Model Artifact\n        # 2. Predictions\n        model_out = f\"{base_gcs_path}/output/{loop_id}/training/proxy_model.json\"\n        pred_out = f\"{base_gcs_path}/output/{loop_id}/training/proxy_predictions.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/train_xgboost.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 train_xgboost.py \"\n            f\"--train {labeled} \"\n            f\"--predict {pool} \"\n            f\"--output_model {model_out} \"\n            f\"--output_predictions {pred_out}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"elite_selector\":\n        # Input: Predictions\n        inp = f\"{base_gcs_path}/output/{loop_id}/training/proxy_predictions.csv\"\n        # Output: Elite Candidates\n        out = f\"{base_gcs_path}/output/{loop_id}/selection_v2/elite_candidates.csv\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/select_elite.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 select_elite.py \"\n            f\"--predictions {inp} \"\n            f\"--output {out} \"\n            f\"--n_elite 40 --n_random 10\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"redocker\":\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection_v2/elite_candidates.csv\"\n        out_dir = f\"{base_gcs_path}/output/{loop_id}/training_data/sdfs\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/redock_batch.py\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 redock_batch.py \"\n            f\"--input {inp} \"\n            f\"--output_dir {out_dir}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"finetune_launcher\":\n        data_dir = f\"{base_gcs_path}/output/{loop_id}/training_data/sdfs\"\n        # Model output will be a new directory for next cycle\n        model_out_dir = f\"{base_gcs_path}/output/{loop_id}/models/finetuned\"\n\n        script_src = f\"{base_gcs_path}/data/scripts/finetune_launcher.py\"\n\n        # Params for launcher\n        proj = \"gcda-apac-sc\"\n        reg = \"us-central1\"\n\n        cmd_str = (\n            f\"cp {script_src} . && \"\n            f\"python3 finetune_launcher.py \"\n            f\"--project {proj} \"\n            f\"--region {reg} \"\n            f\"--training_data_dir {data_dir} \"\n            f\"--output_model_dir {model_out_dir}\"\n            f\"--output_model_dir {model_out_dir}\"\n        )\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    elif mode == \"mmpbsa_fep\":\n        # Input: Candidates from selection\n        inp = f\"{base_gcs_path}/output/{loop_id}/selection/selected_candidates.csv\"\n        # Output: Results directory (CSV created inside)\n        out = f\"{base_gcs_path}/output/{loop_id}/oracle\"\n\n        # Original: /usr/local/bin/run_mmpbsa.sh --run --id batch_${BATCH_TASK_INDEX}\n        # We need to inject runtime copying of scripts? \n        # Actually, let's keep it simple: Ensure spec mounts correct paths or we override commands.\n        # The spec `mmpbsa-test-job.json` has `cp .../fep_setup.py` hardcoded.\n        # For pipeline, we should assume scripts are in `scripts/` or `input/`.\n\n        # Let's construct a command that:\n        # 1. Copies `fep_setup.py` and `run_mmpbsa.sh` from `scripts/`? \n        #    Or assume they are baked in image? Current status: Baked in image BUT we hotfix them.\n        #    Safe bet: Copy from GCS location defined in `BASE_GCS_PATH`.\n\n        script_dir = f\"{base_gcs_path}/data/scripts/mmpbsa_shards\"\n\n        # Command construction\n        # Note: We need to preserve BATCH_TASK_INDEX env var usage\n        cmd_str = (\n            f\"cp {script_dir}/fep_setup.py /usr/local/bin/fep_setup.py && \"\n            f\"cp {script_dir}/run_mmpbsa.sh /usr/local/bin/run_mmpbsa.sh && \"\n            f\"chmod +x /usr/local/bin/run_mmpbsa.sh /usr/local/bin/fep_setup.py && \"\n            f\"export BATCH_TASK_INDEX=${{BATCH_TASK_INDEX}} && \"\n            f\"/usr/local/bin/run_mmpbsa.sh --run --id batch_${{BATCH_TASK_INDEX}}\"\n        )\n\n        # Update mounts to point to dynamic loop paths if needed?\n        # Actually, mmpbsa READS from `INPUT_DIR`.\n        # By default `INPUT_DIR` is `/mnt/disks/gcs/input`.\n        # We need to ensure that `selected_candidates.csv` is split into `batch_N.csv` there?\n        # OR `run_mmpbsa.sh` reads `batch_N.csv`.\n        # Pipeline Gap: Who splits `selected_candidates.csv` into `batch_0.csv`?\n        # Answer: `stage_mmpbsa_batch` component? Or `selection` step?\n        # Current workflow test used `stage_mmpbsa_test.py`.\n        # We need a `staging` step in pipeline or `selection` output split.\n        # For now, let's assume `selection` outputs a single file and we execute ONE big batch or `run_mmpbsa` handles splitting?\n        # No, `run_mmpbsa.sh` expects `${JOB_ID}.csv`.\n        # We will add a \"Stager\" component later. For integration, we define the hook here.\n\n        container['commands'] = [\"/bin/bash\", \"-c\", cmd_str]\n\n    return json.dumps(spec)\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-submit-batch-job": {
        "container": {
          "args": [
            "{{$.inputs.parameters['project']}}",
            "{{$.inputs.parameters['location']}}",
            "{{$.inputs.parameters['job_spec']}}"
          ],
          "command": [
            "sh",
            "-c",
            "\n            set -e -x\n\n            # Create a temporary file for the job spec\n            JOB_SPEC_FILE=$(mktemp)\n            echo \"$2\" > \"$JOB_SPEC_FILE\"\n\n            # Authenticate using the environment's service account\n            gcloud auth application-default print-access-token > /tmp/token\n            export CLOUDSDK_AUTH_ACCESS_TOKEN=$(cat /tmp/token)\n\n            # --- CORRECTED AND ROBUST JOB NAME ---\n            # This command creates a short, random, alphanumeric string that is safe for job names.\n            RANDOM_SUFFIX=$(head /dev/urandom | tr -dc a-z0-9 | head -c 8)\n            JOB_NAME=\"pipeline-job-$(date +%s)-${RANDOM_SUFFIX}\"\n            echo \"Submitting Batch job: ${JOB_NAME}\"\n\n            # Submit the job using the correct '--config' flag\n            gcloud beta batch jobs submit ${JOB_NAME} \\\n                --project=\"$0\" \\\n                --location=\"$1\" \\\n                --config=\"$JOB_SPEC_FILE\"\n\n            echo \"Job submitted. Now polling for completion...\"\n\n            # Loop until the job is no longer in a 'RUNNING' or 'QUEUED' state.\n            while true; do\n                # Get the job's state.\n                JOB_STATE=$(gcloud beta batch jobs describe ${JOB_NAME} \\\n                    --project=\"$0\" \\\n                    --location=\"$1\" \\\n                    --format=\"value(status.state)\")\n\n                echo \"Current job state: ${JOB_STATE}\"\n\n                if [ \"${JOB_STATE}\" = \"SUCCEEDED\" ]; then\n                    echo \"Job ${JOB_NAME} succeeded.\"\n                    exit 0\n                elif [ \"${JOB_STATE}\" = \"FAILED\" ]; then\n                    echo \"Job ${JOB_NAME} failed.\"\n                    exit 1\n                elif [ \"${JOB_STATE}\" = \"DELETED\" ]; then\n                    echo \"Job ${JOB_NAME} was deleted.\"\n                    exit 1\n                fi\n\n                # Wait for 30 seconds before checking again\n                sleep 30\n            done\n            "
          ],
          "image": "gcr.io/google.com/cloudsdktool/cloud-sdk:latest"
        }
      },
      "exec-submit-batch-job-10": {
        "container": {
          "args": [
            "{{$.inputs.parameters['project']}}",
            "{{$.inputs.parameters['location']}}",
            "{{$.inputs.parameters['job_spec']}}"
          ],
          "command": [
            "sh",
            "-c",
            "\n            set -e -x\n\n            # Create a temporary file for the job spec\n            JOB_SPEC_FILE=$(mktemp)\n            echo \"$2\" > \"$JOB_SPEC_FILE\"\n\n            # Authenticate using the environment's service account\n            gcloud auth application-default print-access-token > /tmp/token\n            export CLOUDSDK_AUTH_ACCESS_TOKEN=$(cat /tmp/token)\n\n            # --- CORRECTED AND ROBUST JOB NAME ---\n            # This command creates a short, random, alphanumeric string that is safe for job names.\n            RANDOM_SUFFIX=$(head /dev/urandom | tr -dc a-z0-9 | head -c 8)\n            JOB_NAME=\"pipeline-job-$(date +%s)-${RANDOM_SUFFIX}\"\n            echo \"Submitting Batch job: ${JOB_NAME}\"\n\n            # Submit the job using the correct '--config' flag\n            gcloud beta batch jobs submit ${JOB_NAME} \\\n                --project=\"$0\" \\\n                --location=\"$1\" \\\n                --config=\"$JOB_SPEC_FILE\"\n\n            echo \"Job submitted. Now polling for completion...\"\n\n            # Loop until the job is no longer in a 'RUNNING' or 'QUEUED' state.\n            while true; do\n                # Get the job's state.\n                JOB_STATE=$(gcloud beta batch jobs describe ${JOB_NAME} \\\n                    --project=\"$0\" \\\n                    --location=\"$1\" \\\n                    --format=\"value(status.state)\")\n\n                echo \"Current job state: ${JOB_STATE}\"\n\n                if [ \"${JOB_STATE}\" = \"SUCCEEDED\" ]; then\n                    echo \"Job ${JOB_NAME} succeeded.\"\n                    exit 0\n                elif [ \"${JOB_STATE}\" = \"FAILED\" ]; then\n                    echo \"Job ${JOB_NAME} failed.\"\n                    exit 1\n                elif [ \"${JOB_STATE}\" = \"DELETED\" ]; then\n                    echo \"Job ${JOB_NAME} was deleted.\"\n                    exit 1\n                fi\n\n                # Wait for 30 seconds before checking again\n                sleep 30\n            done\n            "
          ],
          "image": "gcr.io/google.com/cloudsdktool/cloud-sdk:latest"
        }
      },
      "exec-submit-batch-job-11": {
        "container": {
          "args": [
            "{{$.inputs.parameters['project']}}",
            "{{$.inputs.parameters['location']}}",
            "{{$.inputs.parameters['job_spec']}}"
          ],
          "command": [
            "sh",
            "-c",
            "\n            set -e -x\n\n            # Create a temporary file for the job spec\n            JOB_SPEC_FILE=$(mktemp)\n            echo \"$2\" > \"$JOB_SPEC_FILE\"\n\n            # Authenticate using the environment's service account\n            gcloud auth application-default print-access-token > /tmp/token\n            export CLOUDSDK_AUTH_ACCESS_TOKEN=$(cat /tmp/token)\n\n            # --- CORRECTED AND ROBUST JOB NAME ---\n            # This command creates a short, random, alphanumeric string that is safe for job names.\n            RANDOM_SUFFIX=$(head /dev/urandom | tr -dc a-z0-9 | head -c 8)\n            JOB_NAME=\"pipeline-job-$(date +%s)-${RANDOM_SUFFIX}\"\n            echo \"Submitting Batch job: ${JOB_NAME}\"\n\n            # Submit the job using the correct '--config' flag\n            gcloud beta batch jobs submit ${JOB_NAME} \\\n                --project=\"$0\" \\\n                --location=\"$1\" \\\n                --config=\"$JOB_SPEC_FILE\"\n\n            echo \"Job submitted. Now polling for completion...\"\n\n            # Loop until the job is no longer in a 'RUNNING' or 'QUEUED' state.\n            while true; do\n                # Get the job's state.\n                JOB_STATE=$(gcloud beta batch jobs describe ${JOB_NAME} \\\n                    --project=\"$0\" \\\n                    --location=\"$1\" \\\n                    --format=\"value(status.state)\")\n\n                echo \"Current job state: ${JOB_STATE}\"\n\n                if [ \"${JOB_STATE}\" = \"SUCCEEDED\" ]; then\n                    echo \"Job ${JOB_NAME} succeeded.\"\n                    exit 0\n                elif [ \"${JOB_STATE}\" = \"FAILED\" ]; then\n                    echo \"Job ${JOB_NAME} failed.\"\n                    exit 1\n                elif [ \"${JOB_STATE}\" = \"DELETED\" ]; then\n                    echo \"Job ${JOB_NAME} was deleted.\"\n                    exit 1\n                fi\n\n                # Wait for 30 seconds before checking again\n                sleep 30\n            done\n            "
          ],
          "image": "gcr.io/google.com/cloudsdktool/cloud-sdk:latest"
        }
      },
      "exec-submit-batch-job-2": {
        "container": {
          "args": [
            "{{$.inputs.parameters['project']}}",
            "{{$.inputs.parameters['location']}}",
            "{{$.inputs.parameters['job_spec']}}"
          ],
          "command": [
            "sh",
            "-c",
            "\n            set -e -x\n\n            # Create a temporary file for the job spec\n            JOB_SPEC_FILE=$(mktemp)\n            echo \"$2\" > \"$JOB_SPEC_FILE\"\n\n            # Authenticate using the environment's service account\n            gcloud auth application-default print-access-token > /tmp/token\n            export CLOUDSDK_AUTH_ACCESS_TOKEN=$(cat /tmp/token)\n\n            # --- CORRECTED AND ROBUST JOB NAME ---\n            # This command creates a short, random, alphanumeric string that is safe for job names.\n            RANDOM_SUFFIX=$(head /dev/urandom | tr -dc a-z0-9 | head -c 8)\n            JOB_NAME=\"pipeline-job-$(date +%s)-${RANDOM_SUFFIX}\"\n            echo \"Submitting Batch job: ${JOB_NAME}\"\n\n            # Submit the job using the correct '--config' flag\n            gcloud beta batch jobs submit ${JOB_NAME} \\\n                --project=\"$0\" \\\n                --location=\"$1\" \\\n                --config=\"$JOB_SPEC_FILE\"\n\n            echo \"Job submitted. Now polling for completion...\"\n\n            # Loop until the job is no longer in a 'RUNNING' or 'QUEUED' state.\n            while true; do\n                # Get the job's state.\n                JOB_STATE=$(gcloud beta batch jobs describe ${JOB_NAME} \\\n                    --project=\"$0\" \\\n                    --location=\"$1\" \\\n                    --format=\"value(status.state)\")\n\n                echo \"Current job state: ${JOB_STATE}\"\n\n                if [ \"${JOB_STATE}\" = \"SUCCEEDED\" ]; then\n                    echo \"Job ${JOB_NAME} succeeded.\"\n                    exit 0\n                elif [ \"${JOB_STATE}\" = \"FAILED\" ]; then\n                    echo \"Job ${JOB_NAME} failed.\"\n                    exit 1\n                elif [ \"${JOB_STATE}\" = \"DELETED\" ]; then\n                    echo \"Job ${JOB_NAME} was deleted.\"\n                    exit 1\n                fi\n\n                # Wait for 30 seconds before checking again\n                sleep 30\n            done\n            "
          ],
          "image": "gcr.io/google.com/cloudsdktool/cloud-sdk:latest"
        }
      },
      "exec-submit-batch-job-3": {
        "container": {
          "args": [
            "{{$.inputs.parameters['project']}}",
            "{{$.inputs.parameters['location']}}",
            "{{$.inputs.parameters['job_spec']}}"
          ],
          "command": [
            "sh",
            "-c",
            "\n            set -e -x\n\n            # Create a temporary file for the job spec\n            JOB_SPEC_FILE=$(mktemp)\n            echo \"$2\" > \"$JOB_SPEC_FILE\"\n\n            # Authenticate using the environment's service account\n            gcloud auth application-default print-access-token > /tmp/token\n            export CLOUDSDK_AUTH_ACCESS_TOKEN=$(cat /tmp/token)\n\n            # --- CORRECTED AND ROBUST JOB NAME ---\n            # This command creates a short, random, alphanumeric string that is safe for job names.\n            RANDOM_SUFFIX=$(head /dev/urandom | tr -dc a-z0-9 | head -c 8)\n            JOB_NAME=\"pipeline-job-$(date +%s)-${RANDOM_SUFFIX}\"\n            echo \"Submitting Batch job: ${JOB_NAME}\"\n\n            # Submit the job using the correct '--config' flag\n            gcloud beta batch jobs submit ${JOB_NAME} \\\n                --project=\"$0\" \\\n                --location=\"$1\" \\\n                --config=\"$JOB_SPEC_FILE\"\n\n            echo \"Job submitted. Now polling for completion...\"\n\n            # Loop until the job is no longer in a 'RUNNING' or 'QUEUED' state.\n            while true; do\n                # Get the job's state.\n                JOB_STATE=$(gcloud beta batch jobs describe ${JOB_NAME} \\\n                    --project=\"$0\" \\\n                    --location=\"$1\" \\\n                    --format=\"value(status.state)\")\n\n                echo \"Current job state: ${JOB_STATE}\"\n\n                if [ \"${JOB_STATE}\" = \"SUCCEEDED\" ]; then\n                    echo \"Job ${JOB_NAME} succeeded.\"\n                    exit 0\n                elif [ \"${JOB_STATE}\" = \"FAILED\" ]; then\n                    echo \"Job ${JOB_NAME} failed.\"\n                    exit 1\n                elif [ \"${JOB_STATE}\" = \"DELETED\" ]; then\n                    echo \"Job ${JOB_NAME} was deleted.\"\n                    exit 1\n                fi\n\n                # Wait for 30 seconds before checking again\n                sleep 30\n            done\n            "
          ],
          "image": "gcr.io/google.com/cloudsdktool/cloud-sdk:latest"
        }
      },
      "exec-submit-batch-job-4": {
        "container": {
          "args": [
            "{{$.inputs.parameters['project']}}",
            "{{$.inputs.parameters['location']}}",
            "{{$.inputs.parameters['job_spec']}}"
          ],
          "command": [
            "sh",
            "-c",
            "\n            set -e -x\n\n            # Create a temporary file for the job spec\n            JOB_SPEC_FILE=$(mktemp)\n            echo \"$2\" > \"$JOB_SPEC_FILE\"\n\n            # Authenticate using the environment's service account\n            gcloud auth application-default print-access-token > /tmp/token\n            export CLOUDSDK_AUTH_ACCESS_TOKEN=$(cat /tmp/token)\n\n            # --- CORRECTED AND ROBUST JOB NAME ---\n            # This command creates a short, random, alphanumeric string that is safe for job names.\n            RANDOM_SUFFIX=$(head /dev/urandom | tr -dc a-z0-9 | head -c 8)\n            JOB_NAME=\"pipeline-job-$(date +%s)-${RANDOM_SUFFIX}\"\n            echo \"Submitting Batch job: ${JOB_NAME}\"\n\n            # Submit the job using the correct '--config' flag\n            gcloud beta batch jobs submit ${JOB_NAME} \\\n                --project=\"$0\" \\\n                --location=\"$1\" \\\n                --config=\"$JOB_SPEC_FILE\"\n\n            echo \"Job submitted. Now polling for completion...\"\n\n            # Loop until the job is no longer in a 'RUNNING' or 'QUEUED' state.\n            while true; do\n                # Get the job's state.\n                JOB_STATE=$(gcloud beta batch jobs describe ${JOB_NAME} \\\n                    --project=\"$0\" \\\n                    --location=\"$1\" \\\n                    --format=\"value(status.state)\")\n\n                echo \"Current job state: ${JOB_STATE}\"\n\n                if [ \"${JOB_STATE}\" = \"SUCCEEDED\" ]; then\n                    echo \"Job ${JOB_NAME} succeeded.\"\n                    exit 0\n                elif [ \"${JOB_STATE}\" = \"FAILED\" ]; then\n                    echo \"Job ${JOB_NAME} failed.\"\n                    exit 1\n                elif [ \"${JOB_STATE}\" = \"DELETED\" ]; then\n                    echo \"Job ${JOB_NAME} was deleted.\"\n                    exit 1\n                fi\n\n                # Wait for 30 seconds before checking again\n                sleep 30\n            done\n            "
          ],
          "image": "gcr.io/google.com/cloudsdktool/cloud-sdk:latest"
        }
      },
      "exec-submit-batch-job-5": {
        "container": {
          "args": [
            "{{$.inputs.parameters['project']}}",
            "{{$.inputs.parameters['location']}}",
            "{{$.inputs.parameters['job_spec']}}"
          ],
          "command": [
            "sh",
            "-c",
            "\n            set -e -x\n\n            # Create a temporary file for the job spec\n            JOB_SPEC_FILE=$(mktemp)\n            echo \"$2\" > \"$JOB_SPEC_FILE\"\n\n            # Authenticate using the environment's service account\n            gcloud auth application-default print-access-token > /tmp/token\n            export CLOUDSDK_AUTH_ACCESS_TOKEN=$(cat /tmp/token)\n\n            # --- CORRECTED AND ROBUST JOB NAME ---\n            # This command creates a short, random, alphanumeric string that is safe for job names.\n            RANDOM_SUFFIX=$(head /dev/urandom | tr -dc a-z0-9 | head -c 8)\n            JOB_NAME=\"pipeline-job-$(date +%s)-${RANDOM_SUFFIX}\"\n            echo \"Submitting Batch job: ${JOB_NAME}\"\n\n            # Submit the job using the correct '--config' flag\n            gcloud beta batch jobs submit ${JOB_NAME} \\\n                --project=\"$0\" \\\n                --location=\"$1\" \\\n                --config=\"$JOB_SPEC_FILE\"\n\n            echo \"Job submitted. Now polling for completion...\"\n\n            # Loop until the job is no longer in a 'RUNNING' or 'QUEUED' state.\n            while true; do\n                # Get the job's state.\n                JOB_STATE=$(gcloud beta batch jobs describe ${JOB_NAME} \\\n                    --project=\"$0\" \\\n                    --location=\"$1\" \\\n                    --format=\"value(status.state)\")\n\n                echo \"Current job state: ${JOB_STATE}\"\n\n                if [ \"${JOB_STATE}\" = \"SUCCEEDED\" ]; then\n                    echo \"Job ${JOB_NAME} succeeded.\"\n                    exit 0\n                elif [ \"${JOB_STATE}\" = \"FAILED\" ]; then\n                    echo \"Job ${JOB_NAME} failed.\"\n                    exit 1\n                elif [ \"${JOB_STATE}\" = \"DELETED\" ]; then\n                    echo \"Job ${JOB_NAME} was deleted.\"\n                    exit 1\n                fi\n\n                # Wait for 30 seconds before checking again\n                sleep 30\n            done\n            "
          ],
          "image": "gcr.io/google.com/cloudsdktool/cloud-sdk:latest"
        }
      },
      "exec-submit-batch-job-6": {
        "container": {
          "args": [
            "{{$.inputs.parameters['project']}}",
            "{{$.inputs.parameters['location']}}",
            "{{$.inputs.parameters['job_spec']}}"
          ],
          "command": [
            "sh",
            "-c",
            "\n            set -e -x\n\n            # Create a temporary file for the job spec\n            JOB_SPEC_FILE=$(mktemp)\n            echo \"$2\" > \"$JOB_SPEC_FILE\"\n\n            # Authenticate using the environment's service account\n            gcloud auth application-default print-access-token > /tmp/token\n            export CLOUDSDK_AUTH_ACCESS_TOKEN=$(cat /tmp/token)\n\n            # --- CORRECTED AND ROBUST JOB NAME ---\n            # This command creates a short, random, alphanumeric string that is safe for job names.\n            RANDOM_SUFFIX=$(head /dev/urandom | tr -dc a-z0-9 | head -c 8)\n            JOB_NAME=\"pipeline-job-$(date +%s)-${RANDOM_SUFFIX}\"\n            echo \"Submitting Batch job: ${JOB_NAME}\"\n\n            # Submit the job using the correct '--config' flag\n            gcloud beta batch jobs submit ${JOB_NAME} \\\n                --project=\"$0\" \\\n                --location=\"$1\" \\\n                --config=\"$JOB_SPEC_FILE\"\n\n            echo \"Job submitted. Now polling for completion...\"\n\n            # Loop until the job is no longer in a 'RUNNING' or 'QUEUED' state.\n            while true; do\n                # Get the job's state.\n                JOB_STATE=$(gcloud beta batch jobs describe ${JOB_NAME} \\\n                    --project=\"$0\" \\\n                    --location=\"$1\" \\\n                    --format=\"value(status.state)\")\n\n                echo \"Current job state: ${JOB_STATE}\"\n\n                if [ \"${JOB_STATE}\" = \"SUCCEEDED\" ]; then\n                    echo \"Job ${JOB_NAME} succeeded.\"\n                    exit 0\n                elif [ \"${JOB_STATE}\" = \"FAILED\" ]; then\n                    echo \"Job ${JOB_NAME} failed.\"\n                    exit 1\n                elif [ \"${JOB_STATE}\" = \"DELETED\" ]; then\n                    echo \"Job ${JOB_NAME} was deleted.\"\n                    exit 1\n                fi\n\n                # Wait for 30 seconds before checking again\n                sleep 30\n            done\n            "
          ],
          "image": "gcr.io/google.com/cloudsdktool/cloud-sdk:latest"
        }
      },
      "exec-submit-batch-job-7": {
        "container": {
          "args": [
            "{{$.inputs.parameters['project']}}",
            "{{$.inputs.parameters['location']}}",
            "{{$.inputs.parameters['job_spec']}}"
          ],
          "command": [
            "sh",
            "-c",
            "\n            set -e -x\n\n            # Create a temporary file for the job spec\n            JOB_SPEC_FILE=$(mktemp)\n            echo \"$2\" > \"$JOB_SPEC_FILE\"\n\n            # Authenticate using the environment's service account\n            gcloud auth application-default print-access-token > /tmp/token\n            export CLOUDSDK_AUTH_ACCESS_TOKEN=$(cat /tmp/token)\n\n            # --- CORRECTED AND ROBUST JOB NAME ---\n            # This command creates a short, random, alphanumeric string that is safe for job names.\n            RANDOM_SUFFIX=$(head /dev/urandom | tr -dc a-z0-9 | head -c 8)\n            JOB_NAME=\"pipeline-job-$(date +%s)-${RANDOM_SUFFIX}\"\n            echo \"Submitting Batch job: ${JOB_NAME}\"\n\n            # Submit the job using the correct '--config' flag\n            gcloud beta batch jobs submit ${JOB_NAME} \\\n                --project=\"$0\" \\\n                --location=\"$1\" \\\n                --config=\"$JOB_SPEC_FILE\"\n\n            echo \"Job submitted. Now polling for completion...\"\n\n            # Loop until the job is no longer in a 'RUNNING' or 'QUEUED' state.\n            while true; do\n                # Get the job's state.\n                JOB_STATE=$(gcloud beta batch jobs describe ${JOB_NAME} \\\n                    --project=\"$0\" \\\n                    --location=\"$1\" \\\n                    --format=\"value(status.state)\")\n\n                echo \"Current job state: ${JOB_STATE}\"\n\n                if [ \"${JOB_STATE}\" = \"SUCCEEDED\" ]; then\n                    echo \"Job ${JOB_NAME} succeeded.\"\n                    exit 0\n                elif [ \"${JOB_STATE}\" = \"FAILED\" ]; then\n                    echo \"Job ${JOB_NAME} failed.\"\n                    exit 1\n                elif [ \"${JOB_STATE}\" = \"DELETED\" ]; then\n                    echo \"Job ${JOB_NAME} was deleted.\"\n                    exit 1\n                fi\n\n                # Wait for 30 seconds before checking again\n                sleep 30\n            done\n            "
          ],
          "image": "gcr.io/google.com/cloudsdktool/cloud-sdk:latest"
        }
      },
      "exec-submit-batch-job-8": {
        "container": {
          "args": [
            "{{$.inputs.parameters['project']}}",
            "{{$.inputs.parameters['location']}}",
            "{{$.inputs.parameters['job_spec']}}"
          ],
          "command": [
            "sh",
            "-c",
            "\n            set -e -x\n\n            # Create a temporary file for the job spec\n            JOB_SPEC_FILE=$(mktemp)\n            echo \"$2\" > \"$JOB_SPEC_FILE\"\n\n            # Authenticate using the environment's service account\n            gcloud auth application-default print-access-token > /tmp/token\n            export CLOUDSDK_AUTH_ACCESS_TOKEN=$(cat /tmp/token)\n\n            # --- CORRECTED AND ROBUST JOB NAME ---\n            # This command creates a short, random, alphanumeric string that is safe for job names.\n            RANDOM_SUFFIX=$(head /dev/urandom | tr -dc a-z0-9 | head -c 8)\n            JOB_NAME=\"pipeline-job-$(date +%s)-${RANDOM_SUFFIX}\"\n            echo \"Submitting Batch job: ${JOB_NAME}\"\n\n            # Submit the job using the correct '--config' flag\n            gcloud beta batch jobs submit ${JOB_NAME} \\\n                --project=\"$0\" \\\n                --location=\"$1\" \\\n                --config=\"$JOB_SPEC_FILE\"\n\n            echo \"Job submitted. Now polling for completion...\"\n\n            # Loop until the job is no longer in a 'RUNNING' or 'QUEUED' state.\n            while true; do\n                # Get the job's state.\n                JOB_STATE=$(gcloud beta batch jobs describe ${JOB_NAME} \\\n                    --project=\"$0\" \\\n                    --location=\"$1\" \\\n                    --format=\"value(status.state)\")\n\n                echo \"Current job state: ${JOB_STATE}\"\n\n                if [ \"${JOB_STATE}\" = \"SUCCEEDED\" ]; then\n                    echo \"Job ${JOB_NAME} succeeded.\"\n                    exit 0\n                elif [ \"${JOB_STATE}\" = \"FAILED\" ]; then\n                    echo \"Job ${JOB_NAME} failed.\"\n                    exit 1\n                elif [ \"${JOB_STATE}\" = \"DELETED\" ]; then\n                    echo \"Job ${JOB_NAME} was deleted.\"\n                    exit 1\n                fi\n\n                # Wait for 30 seconds before checking again\n                sleep 30\n            done\n            "
          ],
          "image": "gcr.io/google.com/cloudsdktool/cloud-sdk:latest"
        }
      },
      "exec-submit-batch-job-9": {
        "container": {
          "args": [
            "{{$.inputs.parameters['project']}}",
            "{{$.inputs.parameters['location']}}",
            "{{$.inputs.parameters['job_spec']}}"
          ],
          "command": [
            "sh",
            "-c",
            "\n            set -e -x\n\n            # Create a temporary file for the job spec\n            JOB_SPEC_FILE=$(mktemp)\n            echo \"$2\" > \"$JOB_SPEC_FILE\"\n\n            # Authenticate using the environment's service account\n            gcloud auth application-default print-access-token > /tmp/token\n            export CLOUDSDK_AUTH_ACCESS_TOKEN=$(cat /tmp/token)\n\n            # --- CORRECTED AND ROBUST JOB NAME ---\n            # This command creates a short, random, alphanumeric string that is safe for job names.\n            RANDOM_SUFFIX=$(head /dev/urandom | tr -dc a-z0-9 | head -c 8)\n            JOB_NAME=\"pipeline-job-$(date +%s)-${RANDOM_SUFFIX}\"\n            echo \"Submitting Batch job: ${JOB_NAME}\"\n\n            # Submit the job using the correct '--config' flag\n            gcloud beta batch jobs submit ${JOB_NAME} \\\n                --project=\"$0\" \\\n                --location=\"$1\" \\\n                --config=\"$JOB_SPEC_FILE\"\n\n            echo \"Job submitted. Now polling for completion...\"\n\n            # Loop until the job is no longer in a 'RUNNING' or 'QUEUED' state.\n            while true; do\n                # Get the job's state.\n                JOB_STATE=$(gcloud beta batch jobs describe ${JOB_NAME} \\\n                    --project=\"$0\" \\\n                    --location=\"$1\" \\\n                    --format=\"value(status.state)\")\n\n                echo \"Current job state: ${JOB_STATE}\"\n\n                if [ \"${JOB_STATE}\" = \"SUCCEEDED\" ]; then\n                    echo \"Job ${JOB_NAME} succeeded.\"\n                    exit 0\n                elif [ \"${JOB_STATE}\" = \"FAILED\" ]; then\n                    echo \"Job ${JOB_NAME} failed.\"\n                    exit 1\n                elif [ \"${JOB_STATE}\" = \"DELETED\" ]; then\n                    echo \"Job ${JOB_NAME} was deleted.\"\n                    exit 1\n                fi\n\n                # Wait for 30 seconds before checking again\n                sleep 30\n            done\n            "
          ],
          "image": "gcr.io/google.com/cloudsdktool/cloud-sdk:latest"
        }
      }
    }
  },
  "pipelineInfo": {
    "description": "Development Pipeline with Mock Oracle",
    "name": "mock-pipeline"
  },
  "root": {
    "dag": {
      "tasks": {
        "patch-spec": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-patch-spec"
          },
          "inputs": {
            "parameters": {
              "base_gcs_path": {
                "runtimeValue": {
                  "constant": "/mnt/disks/gcs"
                }
              },
              "loop_id": {
                "componentInputParameter": "loop_id"
              },
              "mode": {
                "runtimeValue": {
                  "constant": "pocket2mol"
                }
              },
              "spec_json_str": {
                "runtimeValue": {
                  "constant": "{\n    \"taskGroups\": [\n        {\n            \"taskCount\": 1,\n            \"parallelism\": 1,\n            \"taskSpec\": {\n                \"runnables\": [\n                    {\n                        \"container\": {\n                            \"imageUri\": \"us-central1-docker.pkg.dev/gcda-apac-sc/drug-discovery-containers/pocket2mol:v3\",\n                            \"commands\": [\n                                \"/bin/bash\",\n                                \"-c\",\n                                \"export LD_LIBRARY_PATH=/usr/local/nvidia/lib64:/opt/conda/envs/Pocket2Mol/lib:$LD_LIBRARY_PATH && cp configs/sample_for_pdb.yml /tmp/run_config.yml && sed -i 's|./ckpt/pretrained_Pocket2Mol.pt|/mnt/disks/gcs/input/models/pretrained.pt|g' /tmp/run_config.yml && sed -i 's|num_samples: 100|num_samples: 100000|g' /tmp/run_config.yml && python sample_for_pdb.py --config /tmp/run_config.yml --pdb_path /mnt/disks/gcs/input/1aq1.pdb --center '0.517,27.062,8.972' --outdir /mnt/disks/gcs/output/generated\"\n                            ]\n                        }\n                    }\n                ],\n                \"computeResource\": {\n                    \"cpuMilli\": 4000,\n                    \"memoryMib\": 16384\n                },\n                \"volumes\": [\n                    {\n                        \"gcs\": {\n                            \"remotePath\": \"ryanymt/input\"\n                        },\n                        \"mountPath\": \"/mnt/disks/gcs/input\"\n                    },\n                    {\n                        \"gcs\": {\n                            \"remotePath\": \"ryanymt/output\"\n                        },\n                        \"mountPath\": \"/mnt/disks/gcs/output\"\n                    }\n                ]\n            }\n        }\n    ],\n    \"allocationPolicy\": {\n        \"instances\": [\n            {\n                \"installGpuDrivers\": true,\n                \"policy\": {\n                    \"provisioningModel\": \"SPOT\",\n                    \"machineType\": \"g2-standard-4\",\n                    \"accelerators\": [\n                        {\n                            \"type\": \"nvidia-l4\",\n                            \"count\": \"1\",\n                            \"installGpuDrivers\": true\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"logsPolicy\": {\n        \"destination\": \"CLOUD_LOGGING\"\n    }\n}"
                }
              }
            }
          },
          "taskInfo": {
            "name": "Config: Generation"
          }
        },
        "patch-spec-10": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-patch-spec-10"
          },
          "inputs": {
            "parameters": {
              "base_gcs_path": {
                "runtimeValue": {
                  "constant": "/mnt/disks/gcs"
                }
              },
              "loop_id": {
                "componentInputParameter": "loop_id"
              },
              "mode": {
                "runtimeValue": {
                  "constant": "redocker"
                }
              },
              "spec_json_str": {
                "runtimeValue": {
                  "constant": "{\n    \"taskGroups\": [\n        {\n            \"taskCount\": 1,\n            \"parallelism\": 1,\n            \"taskSpec\": {\n                \"runnables\": [\n                    {\n                        \"container\": {\n                            \"imageUri\": \"us-central1-docker.pkg.dev/gcda-apac-sc/drug-discovery-containers/rdkit:latest\",\n                            \"entrypoint\": \"/bin/bash\",\n                            \"commands\": [\n                                \"-c\",\n                                \"echo 'Starting Redocking...' && cp /mnt/disks/gcs/data/scripts/redock_batch.py . && python3 redock_batch.py\"\n                            ],\n                            \"volumes\": [\n                                \"/mnt/disks/gcs:/mnt/disks/gcs:rw\"\n                            ]\n                        }\n                    }\n                ],\n                \"computeResource\": {\n                    \"cpuMilli\": \"2000\",\n                    \"memoryMib\": \"4000\"\n                },\n                \"volumes\": [\n                    {\n                        \"gcs\": {\n                            \"remotePath\": \"ryanymt/output\"\n                        },\n                        \"mountPath\": \"/mnt/disks/gcs\"\n                    }\n                ]\n            }\n        }\n    ],\n    \"allocationPolicy\": {\n        \"instances\": [\n            {\n                \"policy\": {\n                    \"provisioningModel\": \"SPOT\",\n                    \"bootDisk\": {\n                        \"sizeGb\": \"30\"\n                    },\n                    \"machineType\": \"e2-standard-2\"\n                }\n            }\n        ]\n    },\n    \"logsPolicy\": {\n        \"destination\": \"CLOUD_LOGGING\"\n    }\n}"
                }
              }
            }
          },
          "taskInfo": {
            "name": "Config: Redocker"
          }
        },
        "patch-spec-11": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-patch-spec-11"
          },
          "inputs": {
            "parameters": {
              "base_gcs_path": {
                "runtimeValue": {
                  "constant": "/mnt/disks/gcs"
                }
              },
              "loop_id": {
                "componentInputParameter": "loop_id"
              },
              "mode": {
                "runtimeValue": {
                  "constant": "finetune_launcher"
                }
              },
              "spec_json_str": {
                "runtimeValue": {
                  "constant": "{\n    \"taskGroups\": [\n        {\n            \"taskCount\": 1,\n            \"parallelism\": 1,\n            \"taskSpec\": {\n                \"runnables\": [\n                    {\n                        \"container\": {\n                            \"imageUri\": \"us-central1-docker.pkg.dev/gcda-apac-sc/drug-discovery-containers/proxy-model:latest\",\n                            \"entrypoint\": \"/bin/bash\",\n                            \"commands\": [\n                                \"-c\",\n                                \"echo 'Launching Fine-Tuning Job...' && cp /mnt/disks/gcs/data/scripts/finetune_launcher.py . && python3 finetune_launcher.py\"\n                            ],\n                            \"volumes\": [\n                                \"/mnt/disks/gcs:/mnt/disks/gcs:rw\"\n                            ]\n                        }\n                    }\n                ],\n                \"computeResource\": {\n                    \"cpuMilli\": \"1000\",\n                    \"memoryMib\": \"2000\"\n                },\n                \"volumes\": [\n                    {\n                        \"gcs\": {\n                            \"remotePath\": \"ryanymt/output\"\n                        },\n                        \"mountPath\": \"/mnt/disks/gcs\"\n                    }\n                ]\n            }\n        }\n    ],\n    \"allocationPolicy\": {\n        \"instances\": [\n            {\n                \"policy\": {\n                    \"provisioningModel\": \"SPOT\",\n                    \"bootDisk\": {\n                        \"sizeGb\": \"30\"\n                    },\n                    \"machineType\": \"e2-medium\"\n                }\n            }\n        ]\n    },\n    \"logsPolicy\": {\n        \"destination\": \"CLOUD_LOGGING\"\n    }\n}"
                }
              }
            }
          },
          "taskInfo": {
            "name": "Config: Fine-Tuner"
          }
        },
        "patch-spec-2": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-patch-spec-2"
          },
          "inputs": {
            "parameters": {
              "base_gcs_path": {
                "runtimeValue": {
                  "constant": "/mnt/disks/gcs"
                }
              },
              "loop_id": {
                "componentInputParameter": "loop_id"
              },
              "mode": {
                "runtimeValue": {
                  "constant": "gnina"
                }
              },
              "spec_json_str": {
                "runtimeValue": {
                  "constant": "{\n  \"taskGroups\": [\n    {\n      \"taskCount\": 1,\n      \"parallelism\": 1,\n      \"taskSpec\": {\n        \"runnables\": [\n          {\n            \"container\": {\n              \"imageUri\": \"us-central1-docker.pkg.dev/gcda-apac-sc/drug-discovery-containers/gnina:latest\",\n              \"commands\": [\n                \"/bin/bash\",\n                \"-c\",\n                \"/usr/local/bin/run_gnina_docking.sh /mnt/disks/gcs/input/generated/molecules.csv /mnt/disks/gcs/input/1aki.pdb /mnt/disks/gcs/output/docking_results 0\"\n              ]\n            }\n          }\n        ],\n        \"computeResource\": {\n          \"cpuMilli\": 4000,\n          \"memoryMib\": 16384\n        },\n        \"volumes\": [\n          {\n            \"gcs\": {\n              \"remotePath\": \"ryanymt/input\"\n            },\n            \"mountPath\": \"/mnt/disks/gcs/input\"\n          },\n          {\n            \"gcs\": {\n              \"remotePath\": \"ryanymt/output\"\n            },\n            \"mountPath\": \"/mnt/disks/gcs/output\"\n          },\n          {\n            \"gcs\": {\n              \"remotePath\": \"ryanymt/input\"\n            },\n            \"mountPath\": \"/mnt/disks/gcs/data\"\n          }\n        ]\n      }\n    }\n  ],\n  \"allocationPolicy\": {\n    \"instances\": [\n      {\n        \"installGpuDrivers\": true,\n        \"policy\": {\n          \"provisioningModel\": \"SPOT\",\n          \"bootDisk\": {\n            \"sizeGb\": 100\n          },\n          \"machineType\": \"g2-standard-4\",\n          \"accelerators\": [\n            {\n              \"type\": \"nvidia-l4\",\n              \"count\": \"1\",\n              \"installGpuDrivers\": true\n            }\n          ]\n        }\n      }\n    ]\n  },\n  \"logsPolicy\": {\n    \"destination\": \"CLOUD_LOGGING\"\n  }\n}"
                }
              }
            }
          },
          "taskInfo": {
            "name": "Config: Gnina"
          }
        },
        "patch-spec-3": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-patch-spec-3"
          },
          "inputs": {
            "parameters": {
              "base_gcs_path": {
                "runtimeValue": {
                  "constant": "/mnt/disks/gcs"
                }
              },
              "loop_id": {
                "componentInputParameter": "loop_id"
              },
              "mode": {
                "runtimeValue": {
                  "constant": "txgemma"
                }
              },
              "spec_json_str": {
                "runtimeValue": {
                  "constant": "{\n  \"taskGroups\": [\n    {\n      \"taskCount\": 1,\n      \"parallelism\": 1,\n      \"taskSpec\": {\n        \"runnables\": [\n          {\n            \"container\": {\n              \"imageUri\": \"us-central1-docker.pkg.dev/gcda-apac-sc/drug-discovery-containers/txgemma:v2\",\n              \"entrypoint\": \"/bin/bash\",\n              \"commands\": [\n                \"-c\",\n                \"export LD_LIBRARY_PATH=/usr/local/nvidia/lib64:/usr/local/cuda/lib64:$LD_LIBRARY_PATH && pip install transformers==4.42.4 && cp /mnt/disks/gcs/data/scripts/predict_batched.py /tmp/predict.py && python3 /tmp/predict.py --input-file /mnt/disks/gcs/input/run_config_1aq1.pdb_2025_11_20__02_39_24/SMILES.txt --output-file /mnt/disks/gcs/output/txgemma_results.csv\"\n              ]\n            }\n          }\n        ],\n        \"environment\": {\n          \"variables\": {\n            \"HF_TOKEN\": \"SECRET_PLACEHOLDER\"\n          }\n        },\n        \"computeResource\": {\n          \"cpuMilli\": 4000,\n          \"memoryMib\": 16384\n        },\n        \"volumes\": [\n          {\n            \"gcs\": {\n              \"remotePath\": \"ryanymt/output\"\n            },\n            \"mountPath\": \"/mnt/disks/gcs/input\"\n          },\n          {\n            \"gcs\": {\n              \"remotePath\": \"ryanymt/output\"\n            },\n            \"mountPath\": \"/mnt/disks/gcs/output\"\n          },\n          {\n            \"gcs\": {\n              \"remotePath\": \"ryanymt/input\"\n            },\n            \"mountPath\": \"/mnt/disks/gcs/data\"\n          }\n        ]\n      }\n    }\n  ],\n  \"allocationPolicy\": {\n    \"instances\": [\n      {\n        \"installGpuDrivers\": true,\n        \"policy\": {\n          \"provisioningModel\": \"SPOT\",\n          \"bootDisk\": {\n            \"sizeGb\": 100\n          },\n          \"machineType\": \"g2-standard-24\",\n          \"accelerators\": [\n            {\n              \"type\": \"nvidia-l4\",\n              \"count\": \"2\",\n              \"installGpuDrivers\": true\n            }\n          ]\n        }\n      }\n    ]\n  },\n  \"logsPolicy\": {\n    \"destination\": \"CLOUD_LOGGING\"\n  }\n}"
                }
              }
            }
          },
          "taskInfo": {
            "name": "Config: TxGemma"
          }
        },
        "patch-spec-4": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-patch-spec-4"
          },
          "inputs": {
            "parameters": {
              "base_gcs_path": {
                "runtimeValue": {
                  "constant": "/mnt/disks/gcs"
                }
              },
              "loop_id": {
                "componentInputParameter": "loop_id"
              },
              "mode": {
                "runtimeValue": {
                  "constant": "rdkit"
                }
              },
              "spec_json_str": {
                "runtimeValue": {
                  "constant": "{\n    \"taskGroups\": [\n        {\n            \"taskCount\": 1,\n            \"parallelism\": 1,\n            \"taskSpec\": {\n                \"runnables\": [\n                    {\n                        \"container\": {\n                            \"imageUri\": \"us-central1-docker.pkg.dev/gcda-apac-sc/drug-discovery-containers/rdkit\",\n                            \"commands\": [\n                                \"python\",\n                                \"/app/score.py\",\n                                \"--input_csv\",\n                                \"/mnt/disks/gcs/input/docking_results.csv\",\n                                \"--output_csv\",\n                                \"/mnt/disks/gcs/output/rdkit_scores.csv\"\n                            ]\n                        }\n                    }\n                ],\n                \"computeResource\": {\n                    \"cpuMilli\": 1000,\n                    \"memoryMib\": 2048\n                },\n                \"volumes\": [\n                    {\n                        \"gcs\": {\n                            \"remotePath\": \"ryanymt/output\"\n                        },\n                        \"mountPath\": \"/mnt/disks/gcs/input\"\n                    },\n                    {\n                        \"gcs\": {\n                            \"remotePath\": \"ryanymt/output\"\n                        },\n                        \"mountPath\": \"/mnt/disks/gcs/output\"\n                    }\n                ]\n            }\n        }\n    ],\n    \"allocationPolicy\": {\n        \"instances\": [\n            {\n                \"policy\": {\n                    \"provisioningModel\": \"STANDARD\",\n                    \"machineType\": \"e2-standard-2\"\n                }\n            }\n        ]\n    },\n    \"logsPolicy\": {\n        \"destination\": \"CLOUD_LOGGING\"\n    }\n}"
                }
              }
            }
          },
          "taskInfo": {
            "name": "Config: RDKit"
          }
        },
        "patch-spec-5": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-patch-spec-5"
          },
          "inputs": {
            "parameters": {
              "base_gcs_path": {
                "runtimeValue": {
                  "constant": "/mnt/disks/gcs"
                }
              },
              "loop_id": {
                "componentInputParameter": "loop_id"
              },
              "mode": {
                "runtimeValue": {
                  "constant": "joiner"
                }
              },
              "spec_json_str": {
                "runtimeValue": {
                  "constant": "{\n  \"taskGroups\": [\n    {\n      \"taskCount\": 1,\n      \"parallelism\": 1,\n      \"taskSpec\": {\n        \"runnables\": [\n          {\n            \"container\": {\n              \"imageUri\": \"us-central1-docker.pkg.dev/gcda-apac-sc/drug-discovery-containers/joiner:v1\",\n              \"entrypoint\": \"python\",\n              \"commands\": [\n                \"-u\",\n                \"/app/join_results.py\",\n                \"--smiles\",\n                \"/mnt/disks/gcs/input/v3_test_generated_4yhj/SMILES.txt\",\n                \"--rdkit\",\n                \"/mnt/disks/gcs/input/rdkit_scores.csv\",\n                \"--txgemma\",\n                \"/mnt/disks/gcs/input/txgemma_results_standalone.csv\",\n                \"--gnina\",\n                \"/mnt/disks/gcs/input/docking_results\",\n                \"--output\",\n                \"/mnt/disks/gcs/output/aggregated_results.csv\",\n                \"--batch_id\",\n                \"v3_test_4yhj\"\n              ],\n              \"volumes\": [\n                \"/mnt/disks/gcs/input:/mnt/disks/gcs/input:rw\",\n                \"/mnt/disks/gcs/output:/mnt/disks/gcs/output:rw\"\n              ]\n            }\n          }\n        ],\n        \"computeResource\": {\n          \"cpuMilli\": 2000,\n          \"memoryMib\": 4096\n        },\n        \"volumes\": [\n          {\n            \"gcs\": {\n              \"remotePath\": \"ryanymt/output\"\n            },\n            \"mountPath\": \"/mnt/disks/gcs/input\"\n          },\n          {\n            \"gcs\": {\n              \"remotePath\": \"ryanymt/output\"\n            },\n            \"mountPath\": \"/mnt/disks/gcs/output\"\n          }\n        ]\n      }\n    }\n  ],\n  \"allocationPolicy\": {\n    \"instances\": [\n      {\n        \"policy\": {\n          \"machineType\": \"n1-standard-2\",\n          \"provisioningModel\": \"STANDARD\"\n        }\n      }\n    ],\n    \"serviceAccount\": {\n      \"email\": \"1019380215650-compute@developer.gserviceaccount.com\",\n      \"scopes\": [\n        \"https://www.googleapis.com/auth/cloud-platform\"\n      ]\n    }\n  },\n  \"logsPolicy\": {\n    \"destination\": \"CLOUD_LOGGING\"\n  }\n}"
                }
              }
            }
          },
          "taskInfo": {
            "name": "Config: Joiner"
          }
        },
        "patch-spec-6": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-patch-spec-6"
          },
          "inputs": {
            "parameters": {
              "base_gcs_path": {
                "runtimeValue": {
                  "constant": "/mnt/disks/gcs"
                }
              },
              "loop_id": {
                "componentInputParameter": "loop_id"
              },
              "mode": {
                "runtimeValue": {
                  "constant": "selection"
                }
              },
              "spec_json_str": {
                "runtimeValue": {
                  "constant": "{\n  \"taskGroups\": [\n    {\n      \"taskCount\": 1,\n      \"parallelism\": 1,\n      \"taskSpec\": {\n        \"runnables\": [\n          {\n            \"container\": {\n              \"imageUri\": \"us-central1-docker.pkg.dev/gcda-apac-sc/drug-discovery-containers/joiner:v1\",\n              \"entrypoint\": \"python\",\n              \"commands\": [\n                \"-u\",\n                \"/app/join_results.py\",\n                \"--smiles\",\n                \"/mnt/disks/gcs/input/v3_test_generated_4yhj/SMILES.txt\",\n                \"--rdkit\",\n                \"/mnt/disks/gcs/input/rdkit_scores.csv\",\n                \"--txgemma\",\n                \"/mnt/disks/gcs/input/txgemma_results_standalone.csv\",\n                \"--gnina\",\n                \"/mnt/disks/gcs/input/docking_results\",\n                \"--output\",\n                \"/mnt/disks/gcs/output/aggregated_results.csv\",\n                \"--batch_id\",\n                \"v3_test_4yhj\"\n              ],\n              \"volumes\": [\n                \"/mnt/disks/gcs/input:/mnt/disks/gcs/input:rw\",\n                \"/mnt/disks/gcs/output:/mnt/disks/gcs/output:rw\"\n              ]\n            }\n          }\n        ],\n        \"computeResource\": {\n          \"cpuMilli\": 2000,\n          \"memoryMib\": 4096\n        },\n        \"volumes\": [\n          {\n            \"gcs\": {\n              \"remotePath\": \"ryanymt/output\"\n            },\n            \"mountPath\": \"/mnt/disks/gcs/input\"\n          },\n          {\n            \"gcs\": {\n              \"remotePath\": \"ryanymt/output\"\n            },\n            \"mountPath\": \"/mnt/disks/gcs/output\"\n          }\n        ]\n      }\n    }\n  ],\n  \"allocationPolicy\": {\n    \"instances\": [\n      {\n        \"policy\": {\n          \"machineType\": \"n1-standard-2\",\n          \"provisioningModel\": \"STANDARD\"\n        }\n      }\n    ],\n    \"serviceAccount\": {\n      \"email\": \"1019380215650-compute@developer.gserviceaccount.com\",\n      \"scopes\": [\n        \"https://www.googleapis.com/auth/cloud-platform\"\n      ]\n    }\n  },\n  \"logsPolicy\": {\n    \"destination\": \"CLOUD_LOGGING\"\n  }\n}"
                }
              }
            }
          },
          "taskInfo": {
            "name": "Config: Selection"
          }
        },
        "patch-spec-7": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-patch-spec-7"
          },
          "inputs": {
            "parameters": {
              "base_gcs_path": {
                "runtimeValue": {
                  "constant": "/mnt/disks/gcs"
                }
              },
              "loop_id": {
                "componentInputParameter": "loop_id"
              },
              "mode": {
                "runtimeValue": {
                  "constant": "mock_fep"
                }
              },
              "spec_json_str": {
                "runtimeValue": {
                  "constant": "{\n    \"taskGroups\": [\n        {\n            \"taskCount\": 1,\n            \"parallelism\": 1,\n            \"taskSpec\": {\n                \"runnables\": [\n                    {\n                        \"container\": {\n                            \"imageUri\": \"us-central1-docker.pkg.dev/gcda-apac-sc/drug-discovery-containers/proxy-model:latest\",\n                            \"entrypoint\": \"/bin/bash\",\n                            \"commands\": [\n                                \"-c\",\n                                \"echo 'Starting Mock FEP...' && cp /mnt/disks/gcs/data/scripts/mock_fep_batch.py /tmp/mock_fep.py && python3 /tmp/mock_fep.py --input /mnt/disks/gcs/input/selected_candidates.csv\"\n                            ],\n                            \"volumes\": [\n                                \"/mnt/disks/gcs:/mnt/disks/gcs:rw\"\n                            ]\n                        }\n                    }\n                ],\n                \"computeResource\": {\n                    \"cpuMilli\": \"2000\",\n                    \"memoryMib\": \"4000\"\n                },\n                \"volumes\": [\n                    {\n                        \"gcs\": {\n                            \"remotePath\": \"ryanymt/output\"\n                        },\n                        \"mountPath\": \"/mnt/disks/gcs\"\n                    }\n                ]\n            }\n        }\n    ],\n    \"allocationPolicy\": {\n        \"instances\": [\n            {\n                \"policy\": {\n                    \"provisioningModel\": \"SPOT\",\n                    \"bootDisk\": {\n                        \"sizeGb\": \"30\"\n                    },\n                    \"machineType\": \"e2-standard-2\"\n                }\n            }\n        ]\n    },\n    \"logsPolicy\": {\n        \"destination\": \"CLOUD_LOGGING\"\n    }\n}"
                }
              }
            }
          },
          "taskInfo": {
            "name": "Config: Mock Oracle"
          }
        },
        "patch-spec-8": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-patch-spec-8"
          },
          "inputs": {
            "parameters": {
              "base_gcs_path": {
                "runtimeValue": {
                  "constant": "/mnt/disks/gcs"
                }
              },
              "loop_id": {
                "componentInputParameter": "loop_id"
              },
              "mode": {
                "runtimeValue": {
                  "constant": "trainer"
                }
              },
              "spec_json_str": {
                "runtimeValue": {
                  "constant": "{\n    \"taskGroups\": [\n        {\n            \"taskCount\": 1,\n            \"parallelism\": 1,\n            \"taskSpec\": {\n                \"runnables\": [\n                    {\n                        \"container\": {\n                            \"imageUri\": \"us-central1-docker.pkg.dev/gcda-apac-sc/drug-discovery-containers/proxy-model:latest\",\n                            \"entrypoint\": \"/bin/bash\",\n                            \"commands\": [\n                                \"-c\",\n                                \"echo 'Starting XGBoost Trainer...' && cp /mnt/disks/gcs/data/scripts/train_xgboost.py . && python3 train_xgboost.py\"\n                            ],\n                            \"volumes\": [\n                                \"/mnt/disks/gcs:/mnt/disks/gcs:rw\"\n                            ]\n                        }\n                    }\n                ],\n                \"computeResource\": {\n                    \"cpuMilli\": \"2000\",\n                    \"memoryMib\": \"8000\"\n                },\n                \"volumes\": [\n                    {\n                        \"gcs\": {\n                            \"remotePath\": \"ryanymt/output\"\n                        },\n                        \"mountPath\": \"/mnt/disks/gcs\"\n                    }\n                ]\n            }\n        }\n    ],\n    \"allocationPolicy\": {\n        \"instances\": [\n            {\n                \"policy\": {\n                    \"provisioningModel\": \"SPOT\",\n                    \"bootDisk\": {\n                        \"sizeGb\": \"30\"\n                    },\n                    \"machineType\": \"e2-standard-2\"\n                }\n            }\n        ]\n    },\n    \"logsPolicy\": {\n        \"destination\": \"CLOUD_LOGGING\"\n    }\n}"
                }
              }
            }
          },
          "taskInfo": {
            "name": "Config: XGBoost Trainer"
          }
        },
        "patch-spec-9": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-patch-spec-9"
          },
          "inputs": {
            "parameters": {
              "base_gcs_path": {
                "runtimeValue": {
                  "constant": "/mnt/disks/gcs"
                }
              },
              "loop_id": {
                "componentInputParameter": "loop_id"
              },
              "mode": {
                "runtimeValue": {
                  "constant": "elite_selector"
                }
              },
              "spec_json_str": {
                "runtimeValue": {
                  "constant": "{\n    \"taskGroups\": [\n        {\n            \"taskCount\": 1,\n            \"parallelism\": 1,\n            \"taskSpec\": {\n                \"runnables\": [\n                    {\n                        \"container\": {\n                            \"imageUri\": \"us-central1-docker.pkg.dev/gcda-apac-sc/drug-discovery-containers/proxy-model:latest\",\n                            \"entrypoint\": \"/bin/bash\",\n                            \"commands\": [\n                                \"-c\",\n                                \"echo 'Starting Elite Selection...' && cp /mnt/disks/gcs/data/scripts/select_elite.py . && python3 select_elite.py\"\n                            ],\n                            \"volumes\": [\n                                \"/mnt/disks/gcs:/mnt/disks/gcs:rw\"\n                            ]\n                        }\n                    }\n                ],\n                \"computeResource\": {\n                    \"cpuMilli\": \"1000\",\n                    \"memoryMib\": \"2000\"\n                },\n                \"volumes\": [\n                    {\n                        \"gcs\": {\n                            \"remotePath\": \"ryanymt/output\"\n                        },\n                        \"mountPath\": \"/mnt/disks/gcs\"\n                    }\n                ]\n            }\n        }\n    ],\n    \"allocationPolicy\": {\n        \"instances\": [\n            {\n                \"policy\": {\n                    \"provisioningModel\": \"SPOT\",\n                    \"bootDisk\": {\n                        \"sizeGb\": \"30\"\n                    },\n                    \"machineType\": \"e2-medium\"\n                }\n            }\n        ]\n    },\n    \"logsPolicy\": {\n        \"destination\": \"CLOUD_LOGGING\"\n    }\n}"
                }
              }
            }
          },
          "taskInfo": {
            "name": "Config: Elite Selector"
          }
        },
        "submit-batch-job": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-submit-batch-job"
          },
          "dependentTasks": [
            "patch-spec"
          ],
          "inputs": {
            "parameters": {
              "job_spec": {
                "taskOutputParameter": {
                  "outputParameterKey": "Output",
                  "producerTask": "patch-spec"
                }
              },
              "location": {
                "runtimeValue": {
                  "constant": "us-central1"
                }
              },
              "project": {
                "runtimeValue": {
                  "constant": "gcda-apac-sc"
                }
              }
            }
          },
          "taskInfo": {
            "name": "1. Generation"
          }
        },
        "submit-batch-job-10": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-submit-batch-job-10"
          },
          "dependentTasks": [
            "patch-spec-10",
            "submit-batch-job-9"
          ],
          "inputs": {
            "parameters": {
              "job_spec": {
                "taskOutputParameter": {
                  "outputParameterKey": "Output",
                  "producerTask": "patch-spec-10"
                }
              },
              "location": {
                "runtimeValue": {
                  "constant": "us-central1"
                }
              },
              "project": {
                "runtimeValue": {
                  "constant": "gcda-apac-sc"
                }
              }
            }
          },
          "taskInfo": {
            "name": "8. Redocker"
          }
        },
        "submit-batch-job-11": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-submit-batch-job-11"
          },
          "dependentTasks": [
            "patch-spec-11",
            "submit-batch-job-10"
          ],
          "inputs": {
            "parameters": {
              "job_spec": {
                "taskOutputParameter": {
                  "outputParameterKey": "Output",
                  "producerTask": "patch-spec-11"
                }
              },
              "location": {
                "runtimeValue": {
                  "constant": "us-central1"
                }
              },
              "project": {
                "runtimeValue": {
                  "constant": "gcda-apac-sc"
                }
              }
            }
          },
          "taskInfo": {
            "name": "9. Fine-Tuner"
          }
        },
        "submit-batch-job-2": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-submit-batch-job-2"
          },
          "dependentTasks": [
            "patch-spec-2",
            "submit-batch-job"
          ],
          "inputs": {
            "parameters": {
              "job_spec": {
                "taskOutputParameter": {
                  "outputParameterKey": "Output",
                  "producerTask": "patch-spec-2"
                }
              },
              "location": {
                "runtimeValue": {
                  "constant": "us-central1"
                }
              },
              "project": {
                "runtimeValue": {
                  "constant": "gcda-apac-sc"
                }
              }
            }
          },
          "taskInfo": {
            "name": "2a. Filter (Gnina)"
          }
        },
        "submit-batch-job-3": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-submit-batch-job-3"
          },
          "dependentTasks": [
            "patch-spec-3",
            "submit-batch-job"
          ],
          "inputs": {
            "parameters": {
              "job_spec": {
                "taskOutputParameter": {
                  "outputParameterKey": "Output",
                  "producerTask": "patch-spec-3"
                }
              },
              "location": {
                "runtimeValue": {
                  "constant": "us-central1"
                }
              },
              "project": {
                "runtimeValue": {
                  "constant": "gcda-apac-sc"
                }
              }
            }
          },
          "taskInfo": {
            "name": "2b. Filter (TxGemma)"
          }
        },
        "submit-batch-job-4": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-submit-batch-job-4"
          },
          "dependentTasks": [
            "patch-spec-4",
            "submit-batch-job"
          ],
          "inputs": {
            "parameters": {
              "job_spec": {
                "taskOutputParameter": {
                  "outputParameterKey": "Output",
                  "producerTask": "patch-spec-4"
                }
              },
              "location": {
                "runtimeValue": {
                  "constant": "us-central1"
                }
              },
              "project": {
                "runtimeValue": {
                  "constant": "gcda-apac-sc"
                }
              }
            }
          },
          "taskInfo": {
            "name": "2c. Filter (RDKit)"
          }
        },
        "submit-batch-job-5": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-submit-batch-job-5"
          },
          "dependentTasks": [
            "patch-spec-5",
            "submit-batch-job-2",
            "submit-batch-job-3",
            "submit-batch-job-4"
          ],
          "inputs": {
            "parameters": {
              "job_spec": {
                "taskOutputParameter": {
                  "outputParameterKey": "Output",
                  "producerTask": "patch-spec-5"
                }
              },
              "location": {
                "runtimeValue": {
                  "constant": "us-central1"
                }
              },
              "project": {
                "runtimeValue": {
                  "constant": "gcda-apac-sc"
                }
              }
            }
          },
          "taskInfo": {
            "name": "3. Data Joiner"
          }
        },
        "submit-batch-job-6": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-submit-batch-job-6"
          },
          "dependentTasks": [
            "patch-spec-6",
            "submit-batch-job-5"
          ],
          "inputs": {
            "parameters": {
              "job_spec": {
                "taskOutputParameter": {
                  "outputParameterKey": "Output",
                  "producerTask": "patch-spec-6"
                }
              },
              "location": {
                "runtimeValue": {
                  "constant": "us-central1"
                }
              },
              "project": {
                "runtimeValue": {
                  "constant": "gcda-apac-sc"
                }
              }
            }
          },
          "taskInfo": {
            "name": "4. Selection"
          }
        },
        "submit-batch-job-7": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-submit-batch-job-7"
          },
          "dependentTasks": [
            "patch-spec-7",
            "submit-batch-job-6"
          ],
          "inputs": {
            "parameters": {
              "job_spec": {
                "taskOutputParameter": {
                  "outputParameterKey": "Output",
                  "producerTask": "patch-spec-7"
                }
              },
              "location": {
                "runtimeValue": {
                  "constant": "us-central1"
                }
              },
              "project": {
                "runtimeValue": {
                  "constant": "gcda-apac-sc"
                }
              }
            }
          },
          "taskInfo": {
            "name": "Oracle (Mock)"
          }
        },
        "submit-batch-job-8": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-submit-batch-job-8"
          },
          "dependentTasks": [
            "patch-spec-8",
            "submit-batch-job-7"
          ],
          "inputs": {
            "parameters": {
              "job_spec": {
                "taskOutputParameter": {
                  "outputParameterKey": "Output",
                  "producerTask": "patch-spec-8"
                }
              },
              "location": {
                "runtimeValue": {
                  "constant": "us-central1"
                }
              },
              "project": {
                "runtimeValue": {
                  "constant": "gcda-apac-sc"
                }
              }
            }
          },
          "taskInfo": {
            "name": "6. Trainer (XGBoost)"
          }
        },
        "submit-batch-job-9": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-submit-batch-job-9"
          },
          "dependentTasks": [
            "patch-spec-9",
            "submit-batch-job-8"
          ],
          "inputs": {
            "parameters": {
              "job_spec": {
                "taskOutputParameter": {
                  "outputParameterKey": "Output",
                  "producerTask": "patch-spec-9"
                }
              },
              "location": {
                "runtimeValue": {
                  "constant": "us-central1"
                }
              },
              "project": {
                "runtimeValue": {
                  "constant": "gcda-apac-sc"
                }
              }
            }
          },
          "taskInfo": {
            "name": "7. Elite Selector"
          }
        }
      }
    },
    "inputDefinitions": {
      "parameters": {
        "loop_id": {
          "defaultValue": "dev_loop_v1",
          "isOptional": true,
          "parameterType": "STRING"
        }
      }
    }
  },
  "schemaVersion": "2.1.0",
  "sdkVersion": "kfp-2.15.2"
}